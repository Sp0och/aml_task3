{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-21 14:38:59.239609: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from tensorflow import keras\n",
    "from matplotlib import animation\n",
    "from skimage.measure import label, regionprops\n",
    "import random\n",
    "# installation: pip install elasticdeform\n",
    "import elasticdeform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_zipped_pickle(filename):\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        loaded_object = pickle.load(f)\n",
    "        return loaded_object\n",
    "\n",
    "\n",
    "\n",
    "def save_zipped_pickle(obj, filename):\n",
    "    with gzip.open(filename, 'wb') as f:\n",
    "        pickle.dump(obj, f, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(predictions, targets):\n",
    "    ious = []\n",
    "    for p, t in zip(predictions, targets):\n",
    "        assert p['name'] == t['name']\n",
    "        prediction = np.array(p['prediction'], dtype=bool)\n",
    "        target = np.array(t['label'], dtype=bool)\n",
    "\n",
    "        assert target.shape == prediction.shape\n",
    "        overlap = prediction * target\n",
    "        union = prediction + target\n",
    "\n",
    "        ious.append(overlap.sum() / float(union.sum()))\n",
    "\n",
    "    print(\"Median IOU: \", np.median(ious))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_conv_block(x, n_filters):\n",
    "   x = layers.Conv2D(n_filters, 3, padding=\"same\")(x)#kernel_initializer = \"he_normal\"\n",
    "   x = layers.BatchNormalization()(x)\n",
    "   x = layers.ReLU()(x)\n",
    "   x = layers.Conv2D(n_filters, 3, padding=\"same\")(x)#kernel_initializer = \"he_normal\"\n",
    "   x = layers.BatchNormalization()(x)\n",
    "   x = layers.ReLU()(x)\n",
    "   return x\n",
    "\n",
    "\n",
    "def downsample_block(x, n_filters):\n",
    "    f = double_conv_block(x, n_filters)\n",
    "    p = layers.MaxPool2D(2)(f)\n",
    "    # p = layers.Dropout(0.3)(p)\n",
    "    return f, p\n",
    "\n",
    "\n",
    "def upsample_block(x, conv_features, n_filters):\n",
    "    x = layers.Conv2DTranspose(n_filters, 2, 2, padding=\"same\")(x)\n",
    "    x = layers.concatenate([x, conv_features])\n",
    "    # x = layers.Dropout(0.3)(x)\n",
    "    x = double_conv_block(x, n_filters)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(img_size):\n",
    "    inputs = layers.Input(shape=img_size + (1,))\n",
    "    m = 2\n",
    "    f1, p1 = downsample_block(inputs, 16*m)\n",
    "    f2, p2 = downsample_block(p1, 32*m)\n",
    "    f3, p3 = downsample_block(p2, 64*m)\n",
    "    f4, p4 = downsample_block(p3, 128*m)\n",
    "\n",
    "    bottleneck = double_conv_block(p4, 256*m)\n",
    "\n",
    "    u6 = upsample_block(bottleneck, f4, 128*m)\n",
    "    u7 = upsample_block(u6, f3, 64*m)\n",
    "    u8 = upsample_block(u7, f2, 32*m)\n",
    "    u9 = upsample_block(u8, f1, 16*m)\n",
    "\n",
    "    outputs = layers.Conv2D(1, 1, padding=\"valid\", activation=\"sigmoid\")(u9)\n",
    "    unet_model = tf.keras.Model(inputs, outputs, name=\"U-Net\")\n",
    "    return unet_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_distance(y_true, y_pred, smooth=100):\n",
    "    \"\"\"Jaccard distance for semantic segmentation.\n",
    "    The loss has been modified to have a smooth gradient as it converges on zero.\n",
    "    This has been shifted so it converges on 0 and is smoothed to avoid exploding\n",
    "    or disappearing gradient.\n",
    "    Jaccard = (|X & Y|)/ (|X|+ |Y| - |X & Y|)\n",
    "            = sum(|A*B|)/(sum(|A|)+sum(|B|)-sum(|A*B|))\n",
    "\n",
    "    # https://github.com/karolzak/keras-unet/tree/master/keras_unet\n",
    "    \"\"\"\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return (1 - jac) * smooth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_coef(y_true, y_pred):\n",
    "    intersection = K.sum(y_true * y_pred)\n",
    "    union = K.sum(y_true + y_pred)\n",
    "    jac = (intersection + 1.) / (union - intersection + 1.)\n",
    "    return K.mean(jac)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    smooth = 1.0\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_zipped_pickle(\"train.pkl\")\n",
    "test_data = load_zipped_pickle(\"test.pkl\")\n",
    "samples = load_zipped_pickle(\"sample.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_video(img_list):\n",
    "    def init():\n",
    "        img.set_data(img_list[0])\n",
    "        return (img,)\n",
    "\n",
    "    def animate(i):\n",
    "        img.set_data(img_list[i])\n",
    "        return (img,)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca()\n",
    "    img = ax.imshow(img_list[0], cmap='gray', vmin=0, vmax=255)\n",
    "    anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                                   frames=len(img_list), interval=20, blit=True)\n",
    "    return anim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(image, mask):\n",
    "    '''Data augmentation using ImageDataGenerator\n",
    "    \\n data_gen_args = dict(featurewise_center=True,\n",
    "     featurewise_std_normalization=True,'''\n",
    "    seed = 1\n",
    "    # I don't do horizontal_flip bc the mitral valve is in the same side in all videos\n",
    "    data_gen_args = dict(rotation_range=10,\n",
    "                         shear_range=10,\n",
    "                         zoom_range=[0.8, 1.1],\n",
    "                         height_shift_range=0.1,\n",
    "                         width_shift_range=0.1,\n",
    "                         brightness_range=(0.3, 1))\n",
    "\n",
    "    frame_augmentor = ImageDataGenerator(**data_gen_args)\n",
    "    label_augmentor = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "    myimg = image.reshape((1,) + image.shape + (1,))\n",
    "    mask = mask.reshape((1,) + mask.shape + (1,))\n",
    "\n",
    "    aug_frames = frame_augmentor.flow(myimg, seed=seed, batch_size=1)\n",
    "    aug_labels = label_augmentor.flow(mask, seed=seed, batch_size=1)\n",
    "\n",
    "    return aug_frames, aug_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(y_pred, threshold, num_blobs):\n",
    "    '''Remove blobs outside of expected area'''\n",
    "    pruned_pred = np.zeros_like(y_pred)\n",
    "    THRESHOLD_CENTROID = 1/4 #based on experiments\n",
    "    for i in range(y_pred.shape[0]):\n",
    "        pp = y_pred[i,:,:]\n",
    "        pp = pp > threshold\n",
    "        lab = label(pp)\n",
    "        rps = regionprops(lab)\n",
    "        area_idx = np.argsort([r.area for r in rps])[::-1]\n",
    "        new_pp = np.zeros_like(pp)\n",
    "        # Consider the num_blobs largest blobs\n",
    "        for j in area_idx[:num_blobs]:\n",
    "            # If the centroid is close to the centroid of the largest blob, keep it\n",
    "            if np.linalg.norm(np.asarray(rps[area_idx[0]].centroid) - np.asarray(rps[j].centroid))/y_pred.shape[1] < THRESHOLD_CENTROID:\n",
    "                new_pp[tuple(rps[j].coords.T)] = True\n",
    "        pruned_pred[i,:,:] = new_pp\n",
    "\n",
    "    return pruned_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_IoU(y_test, pred):\n",
    "    fehlt = 0\n",
    "    IoU_score = 0\n",
    "    intersection_acc = 0\n",
    "    union_acc = 0\n",
    "    for i in range(pred.shape[0]):\n",
    "        gt = np.squeeze(y_test[i] > 0)\n",
    "        new_pred_i = pred[i]\n",
    "\n",
    "        fehlt += np.count_nonzero(np.logical_and(gt, np.logical_not(new_pred_i)))\n",
    "        intersection = np.count_nonzero(np.logical_and(gt, new_pred_i))\n",
    "        union = np.count_nonzero(np.logical_or(gt, new_pred_i))\n",
    "        intersection_acc += intersection\n",
    "        union_acc += union\n",
    "        IoU_score += intersection/union\n",
    "    return IoU_score/pred.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_train_sample(train_sample_id, labeled_frame_idx):\n",
    "    video = np.copy(train_data[train_sample_id]['video'])\n",
    "    labels = train_data[train_sample_id]['label']\n",
    "    labeled_frames = train_data[train_sample_id]['frames']\n",
    "    X = 0.5*video[:,:,labeled_frames[labeled_frame_idx]] + 0.5*(255*labels[:,:,labeled_frames[labeled_frame_idx]])\n",
    "    plt.imshow(X)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_test_sample(test_sample_id, frame_idx):\n",
    "    video = np.copy(test_data[test_sample_id]['video'])\n",
    "    X = video[:,:,frame_idx]\n",
    "    plt.imshow(X)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_augmentations():\n",
    "    train_sample_id = 1\n",
    "    labeled_frame_idx = 1\n",
    "    crop = False\n",
    "    seed = 1\n",
    "\n",
    "    video = np.copy(train_data[train_sample_id]['video'])\n",
    "    labels = train_data[train_sample_id]['label']\n",
    "    box = train_data[train_sample_id]['box']\n",
    "    labeled_frames = train_data[train_sample_id]['frames']\n",
    "\n",
    "    X = video[:,:,labeled_frames[labeled_frame_idx]]\n",
    "\n",
    "    Y = labels[:,:,labeled_frames[labeled_frame_idx]]\n",
    "\n",
    "    [X_deformed, Y_deformed] = elasticdeform.deform_random_grid([X, Y], sigma=8,  order=1, points=3)\n",
    "\n",
    "    plt.imshow(X_deformed)\n",
    "    plt.imshow(Y_deformed, alpha=0.5)\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 192\n",
    "img_width = 192\n",
    "\n",
    "N_AUG_SIMPLE_PER_SAMPLE = 10   # number of augmentations using ImageDataGeneratir\n",
    "N_AUG_DEFORM_PER_SAMPLE = 10   # number of augmentations using elasticdeform\n",
    "N_AUG_PER_SAMPLE = N_AUG_SIMPLE_PER_SAMPLE + N_AUG_DEFORM_PER_SAMPLE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating scaled and shifted Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "for d in train_data:\n",
    "    for i in d[\"frames\"]:\n",
    "        image = d[\"video\"][:, :, i]\n",
    "        mask = 255 * d[\"label\"][:, :, i].astype(np.ubyte)\n",
    "        x_train.append(cv2.resize(image, dsize=(img_height, img_width)))\n",
    "        y_train.append(cv2.resize(mask, dsize=(img_height, img_width)))\n",
    "        aug_images, aug_masks = augment_data(image, mask)\n",
    "        for tt in range(N_AUG_SIMPLE_PER_SAMPLE):\n",
    "            x_train.append(cv2.resize(next(aug_images)[0], dsize=(img_height, img_width)))\n",
    "            y_train.append(cv2.resize(next(aug_masks)[0], dsize=(img_height, img_width)))\n",
    "        for tt in range(N_AUG_DEFORM_PER_SAMPLE):\n",
    "            [image_deformed, mask_deformed] = elasticdeform.deform_random_grid([image, mask], sigma=8, order=1, points=3)\n",
    "            x_train.append(cv2.resize(image_deformed, dsize=(img_height, img_width)))\n",
    "            y_train.append(cv2.resize(mask_deformed, dsize=(img_height, img_width)))\n",
    "\n",
    "## Preprocessing: (it helps according to K-fold cross validation results; average score got improved from 0.31 to 0.38)\n",
    "#x_train = (x_train - np.mean(x_train))/np.std(x_train)\n",
    "for i in range(len(x_train)):\n",
    "    x_train[i] = (x_train[i] - np.mean(x_train[i]))/np.std(x_train[i])\n",
    "\n",
    "\n",
    "\n",
    "x_train = np.expand_dims(np.array(x_train, dtype=np.single), 3)\n",
    "y_train = np.expand_dims(np.array(y_train, dtype=np.single), 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train - Val Split\n",
    "Note that we have 3 expert sets in the train dataset to allow for more flexibility when shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SPLITS = 5\n",
    "amateur_idx = []\n",
    "expert_idx = []\n",
    "for ii in range(len(train_data)):\n",
    "    if train_data[ii]['dataset'] == 'amateur':\n",
    "        amateur_idx.append(ii)\n",
    "    else:\n",
    "        expert_idx.append(ii)\n",
    "\n",
    "# this only works for N_SPLITS = 5:\n",
    "train_list = []\n",
    "test_list = []\n",
    "N_SAMPLES_PER_VIDEO = 3*(N_AUG_PER_SAMPLE+1)\n",
    "for fold_no in range(N_SPLITS):\n",
    "    fold_train = amateur_idx[3:] + expert_idx[10:]\n",
    "    fold_test = amateur_idx[:3] + expert_idx[:10]\n",
    "\n",
    "    random.shuffle(expert_idx)\n",
    "    random.shuffle(amateur_idx)\n",
    "    fold_train_ext = np.zeros(N_SAMPLES_PER_VIDEO*len(fold_train))\n",
    "    fold_test_ext = np.zeros(N_SAMPLES_PER_VIDEO*len(fold_test))\n",
    "    for k in range(len(fold_train)):\n",
    "        fold_train_ext[N_SAMPLES_PER_VIDEO*k:N_SAMPLES_PER_VIDEO*(k+1)] = fold_train[k]*N_SAMPLES_PER_VIDEO + np.arange(N_SAMPLES_PER_VIDEO)\n",
    "\n",
    "    for k in range(len(fold_test)):\n",
    "        fold_test_ext[N_SAMPLES_PER_VIDEO*k:N_SAMPLES_PER_VIDEO*(k+1)] = fold_test[k]*N_SAMPLES_PER_VIDEO + np.arange(N_SAMPLES_PER_VIDEO)\n",
    "\n",
    "    TR_L = list(fold_train_ext.astype(int))\n",
    "    random.shuffle(TR_L)\n",
    "    TE_L = list(fold_test_ext.astype(int))\n",
    "    random.shuffle(TE_L)\n",
    "\n",
    "    train_list.append(TR_L)\n",
    "    test_list.append(TE_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4095, 192, 192, 1)\n",
      "(4095, 192, 192, 1)\n",
      "3276\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(len(train_list[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-21 15:10:00.429577: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [25], line 32\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39m#model.summary()\u001b[39;00m\n\u001b[1;32m     24\u001b[0m model\u001b[39m.\u001b[39mcompile(\n\u001b[1;32m     25\u001b[0m     optimizer\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m5e-4\u001b[39m),\n\u001b[1;32m     26\u001b[0m     \u001b[39m# loss=keras.losses.BinaryCrossentropy(),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m     metrics\u001b[39m=\u001b[39m[dice_coef]\n\u001b[1;32m     30\u001b[0m )\n\u001b[0;32m---> 32\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     33\u001b[0m     x_train[train_idx],\n\u001b[1;32m     34\u001b[0m     y_train[train_idx],\n\u001b[1;32m     35\u001b[0m     \u001b[39m# validation_data=(x_train[test_idx], y_train[test_idx]),\u001b[39;49;00m\n\u001b[1;32m     36\u001b[0m     batch_size\u001b[39m=\u001b[39;49mBATCH_SIZE,\n\u001b[1;32m     37\u001b[0m     epochs\u001b[39m=\u001b[39;49mEPOCHS,\n\u001b[1;32m     38\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m\n\u001b[1;32m     39\u001b[0m )\n\u001b[1;32m     40\u001b[0m history_l\u001b[39m.\u001b[39mappend(history)\n\u001b[1;32m     41\u001b[0m pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(x_train[test_idx])\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1651\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1746\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    379\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    380\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    381\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    382\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    383\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    384\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 10\n",
    "fold_no = 0\n",
    "seed = 1\n",
    "scores = []\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "history_l = []\n",
    "# for train_idx, test_idx in KFold(n_splits=5, shuffle=True).split(y_train):\n",
    "for jj in range(len(train_list)):\n",
    "    train_idx = train_list[jj]\n",
    "    test_idx = test_list[jj]\n",
    "    fold_no += 1\n",
    "    print('------------------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    print('------------------------------------------------------------------------------------')\n",
    "\n",
    "    keras.backend.clear_session()\n",
    "    model = get_model((img_height, img_width))\n",
    "    #model.summary()\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=5e-4),\n",
    "        # loss=keras.losses.BinaryCrossentropy(),\n",
    "        # metrics=[jaccard_coef],\n",
    "        loss=dice_coef_loss,\n",
    "        metrics=[dice_coef]\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        x_train[train_idx],\n",
    "        y_train[train_idx],\n",
    "        # validation_data=(x_train[test_idx], y_train[test_idx]),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        verbose=2\n",
    "    )\n",
    "    history_l.append(history)\n",
    "    pred = model.predict(x_train[test_idx])\n",
    "    pred = np.squeeze(pred)\n",
    "\n",
    "    new_pred = post_process(pred, threshold=0.999, num_blobs=2)\n",
    "    score = compute_IoU(y_train[test_idx], new_pred)\n",
    "    scores.append(score)\n",
    "\n",
    "    print(\" -- fold %d score: %f\" %(fold_no, score))\n",
    "    break\n",
    "print(\"Average IoU over folds: %d\", np.mean(scores))\n",
    "#model.save('./save_model')\n",
    "\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
