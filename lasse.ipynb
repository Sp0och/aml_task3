{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "#import os\n",
    "#from PIL import Image as im\n",
    "import cv2\n",
    "#import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import torchdata as td\n",
    "#from torchmetrics.functional import jaccard_index\n",
    "#from tensorflow.keras.utils import to_categorical\n",
    "from PIL import Image as im\n",
    "from skimage.measure import label, regionprops\n",
    "#from sklearn.metrics import f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "#from keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_zipped_pickle(filename):\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        loaded_object = pickle.load(f)\n",
    "        return loaded_object\n",
    "\n",
    "def save_zipped_pickle(obj, filename):\n",
    "    with gzip.open(filename, 'wb') as f:\n",
    "        pickle.dump(obj, f, 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_conv_block_box(x, n_filters):\n",
    "   x = layers.Conv2D(n_filters, 3, padding=\"same\")(x)#kernel_initializer = \"he_normal\"\n",
    "   x = layers.BatchNormalization()(x)\n",
    "   x = layers.ReLU()(x)\n",
    "   x = layers.Conv2D(n_filters, 3, padding=\"same\")(x)#kernel_initializer = \"he_normal\"\n",
    "   x = layers.BatchNormalization()(x)\n",
    "   x = layers.ReLU()(x)\n",
    "   return x\n",
    "\n",
    "def downsample_block_box(x, n_filters):\n",
    "   f = double_conv_block_box(x, n_filters)\n",
    "   p = layers.MaxPool2D(2)(f)\n",
    "   #p = layers.Dropout(0.3)(p)\n",
    "   return f, p\n",
    "\n",
    "def upsample_block_box(x, conv_features, n_filters):\n",
    "   x = layers.Conv2DTranspose(n_filters, 2, 2, padding=\"valid\")(x)\n",
    "   x = layers.concatenate([x, conv_features])\n",
    "   #x = layers.Dropout(0.3)(x)\n",
    "   x = double_conv_block_box(x, n_filters)\n",
    "   return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_box(img_size):\n",
    "    inputs = layers.Input(shape=img_size+(1,))\n",
    "    \n",
    "    f1, p1 = downsample_block_box(inputs, 16)\n",
    "    f2, p2 = downsample_block_box(p1, 32)\n",
    "    f3, p3 = downsample_block_box(p2, 64)\n",
    "    #f4, p4 = downsample_block(p3, 256)\n",
    "    \n",
    "    #bottleneck = double_conv_block(p4, 512)\n",
    "    bottleneck = double_conv_block_box(p3, 128)\n",
    "    \n",
    "    #u6 = upsample_block(bottleneck, f4, 256)\n",
    "    u7 = upsample_block_box(bottleneck, f3, 64)\n",
    "    u8 = upsample_block_box(u7, f2, 32)\n",
    "    u9 = upsample_block_box(u8, f1, 16)\n",
    "\n",
    "    outputs = layers.Conv2D(1, 1, padding=\"valid\", activation = \"sigmoid\")(u9)\n",
    "    \n",
    "    unet_model = tf.keras.Model(inputs, outputs, name=\"U-Net-Box\")\n",
    "    \n",
    "    return unet_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_zipped_pickle(\"train.pkl\")\n",
    "test_data = load_zipped_pickle(\"test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amateur:  46\n",
      "expert:  19\n"
     ]
    }
   ],
   "source": [
    "amateur = 0\n",
    "expert = 0\n",
    "for i in range(len(train_data)):\n",
    "    if train_data[i][\"dataset\"] == \"amateur\":\n",
    "        amateur += 1\n",
    "    else:\n",
    "        expert += 1\n",
    "\n",
    "print(\"amateur: \", amateur)\n",
    "print(\"expert: \", expert)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box\n",
    "Videos have different lengths so consider individual images - each with the same box as label - and increase batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate all video frames into one image\n",
    "x_train_box= []\n",
    "y_train_box = []\n",
    "for dic in train_data:\n",
    "    for i in range(dic[\"video\"].shape[2]):\n",
    "        x_train_box.append(cv2.resize(dic[\"video\"][:,:,i], dsize=(256, 256)))\n",
    "        y_train_box.append(cv2.resize(255 * dic[\"box\"].astype(np.ubyte), dsize=(256, 256)))\n",
    "\n",
    "x_train_box = np.expand_dims(np.array(x_train_box, dtype=np.single), 3)\n",
    "y_train_box = np.expand_dims(np.array(y_train_box, dtype=np.single), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9869\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(y_train_box))\n",
    "plt.imshow(y_train_box[0][:,:,0])\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix seed\n",
    "seed = 1\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9869\n",
      "9869\n",
      "------------------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "------------------------------------------------------------------------------------\n",
      "Model: \"U-Net-Box\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 256, 256, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 256, 256, 16  160         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 256, 256, 16  64         ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                   (None, 256, 256, 16  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 256, 256, 16  2320        ['re_lu[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 256, 256, 16  64         ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_1 (ReLU)                 (None, 256, 256, 16  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 128, 128, 16  0           ['re_lu_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 128, 128, 32  4640        ['max_pooling2d[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 128, 128, 32  128        ['conv2d_2[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_2 (ReLU)                 (None, 128, 128, 32  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 128, 128, 32  9248        ['re_lu_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 128, 128, 32  128        ['conv2d_3[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_3 (ReLU)                 (None, 128, 128, 32  0           ['batch_normalization_3[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 32)  0           ['re_lu_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 64, 64, 64)   18496       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 64, 64, 64)  256         ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_4 (ReLU)                 (None, 64, 64, 64)   0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 64, 64, 64)   36928       ['re_lu_4[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 64, 64, 64)  256         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_5 (ReLU)                 (None, 64, 64, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 64)  0           ['re_lu_5[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 32, 32, 128)  73856       ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 32, 32, 128)  512        ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_6 (ReLU)                 (None, 32, 32, 128)  0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 32, 32, 128)  147584      ['re_lu_6[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 32, 32, 128)  512        ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_7 (ReLU)                 (None, 32, 32, 128)  0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 64, 64, 64)  32832       ['re_lu_7[0][0]']                \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 64, 64, 128)  0           ['conv2d_transpose[0][0]',       \n",
      "                                                                  're_lu_5[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 64, 64, 64)   73792       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 64, 64, 64)  256         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_8 (ReLU)                 (None, 64, 64, 64)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 64, 64, 64)   36928       ['re_lu_8[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 64, 64, 64)  256         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_9 (ReLU)                 (None, 64, 64, 64)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 128, 128, 32  8224       ['re_lu_9[0][0]']                \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 128, 128, 64  0           ['conv2d_transpose_1[0][0]',     \n",
      "                                )                                 're_lu_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 128, 128, 32  18464       ['concatenate_1[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 128, 128, 32  128        ['conv2d_10[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_10 (ReLU)                (None, 128, 128, 32  0           ['batch_normalization_10[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 128, 128, 32  9248        ['re_lu_10[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 128, 128, 32  128        ['conv2d_11[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_11 (ReLU)                (None, 128, 128, 32  0           ['batch_normalization_11[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 256, 256, 16  2064       ['re_lu_11[0][0]']               \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 256, 256, 32  0           ['conv2d_transpose_2[0][0]',     \n",
      "                                )                                 're_lu_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 256, 256, 16  4624        ['concatenate_2[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 256, 256, 16  64         ['conv2d_12[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_12 (ReLU)                (None, 256, 256, 16  0           ['batch_normalization_12[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 256, 256, 16  2320        ['re_lu_12[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 256, 256, 16  64         ['conv2d_13[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_13 (ReLU)                (None, 256, 256, 16  0           ['batch_normalization_13[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 256, 256, 1)  17          ['re_lu_13[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 484,561\n",
      "Trainable params: 483,153\n",
      "Non-trainable params: 1,408\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/8\n",
      "158/158 - 1239s - loss: -2.0223e+02 - accuracy: 0.7157 - val_loss: 0.3200 - val_accuracy: 0.7355 - 1239s/epoch - 8s/step\n",
      "Epoch 2/8\n",
      "158/158 - 1201s - loss: -4.4243e+02 - accuracy: 0.5390 - val_loss: -2.7493e+02 - val_accuracy: 0.6711 - 1201s/epoch - 8s/step\n",
      "Epoch 3/8\n",
      "158/158 - 1124s - loss: -7.6179e+02 - accuracy: 0.5311 - val_loss: -6.6430e+02 - val_accuracy: 0.5517 - 1124s/epoch - 7s/step\n",
      "Epoch 4/8\n",
      "158/158 - 1136s - loss: -1.1761e+03 - accuracy: 0.3162 - val_loss: -1.0903e+03 - val_accuracy: 0.3271 - 1136s/epoch - 7s/step\n",
      "Epoch 5/8\n",
      "158/158 - 1121s - loss: -1.6927e+03 - accuracy: 0.0162 - val_loss: -1.6363e+03 - val_accuracy: 7.4503e-04 - 1121s/epoch - 7s/step\n",
      "Epoch 6/8\n",
      "158/158 - 1126s - loss: -2.3030e+03 - accuracy: 0.0015 - val_loss: -2.4725e+03 - val_accuracy: 4.3107e-04 - 1126s/epoch - 7s/step\n",
      "Epoch 7/8\n",
      "158/158 - 1134s - loss: -3.0035e+03 - accuracy: 0.0058 - val_loss: -3.3445e+03 - val_accuracy: 4.2916e-05 - 1134s/epoch - 7s/step\n",
      "Epoch 8/8\n",
      "158/158 - 1114s - loss: -3.7997e+03 - accuracy: 0.0155 - val_loss: -4.2478e+03 - val_accuracy: 2.5756e-04 - 1114s/epoch - 7s/step\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 8\n",
    "BATCH_SIZE = 50\n",
    "fold_no = 0\n",
    "print(len(x_train_box))\n",
    "print(len(y_train_box))\n",
    "for train_idx, test_idx in KFold(n_splits=5, shuffle=True).split(y_train_box):\n",
    "    \n",
    "    fold_no += 1\n",
    "    print('------------------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    print('------------------------------------------------------------------------------------')\n",
    "    \n",
    "    keras.backend.clear_session()\n",
    "    model = get_model_box((256, 256))\n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        #loss=keras.losses.CategoricalCrossentropy(),\n",
    "        loss=keras.losses.BinaryCrossentropy(),\n",
    "        metrics=[keras.metrics.BinaryAccuracy(name='accuracy')]\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        x_train_box[train_idx],\n",
    "        y_train_box[train_idx],\n",
    "        validation_data=(x_train_box[test_idx], y_train_box[test_idx]),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    #scores = model.evaluate(samples[test_idx], labels[test_idx], verbose=0)\n",
    "    #f1 = f1_score(np.argmax(labels[test_idx], axis=1), np.argmax(model.predict(samples[test_idx]), axis=1), average='micro')\n",
    "    #print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%; f1_score of {f1}')\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_box.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model if already trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model_box.h5\n",
    "# model = tf.keras.models.load_model(\"model_box.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 54s 870ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1974, 256, 256, 1)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(x_train_box[test_idx])\n",
    "x_train_box[test_idx].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get The video lenghts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 333,  510,  705,  886, 1097, 1306, 1435, 1614, 1782, 1933, 2046,\n",
       "       2260, 2411, 2577, 2787, 2905, 3082, 3253, 3511, 3684, 3874, 3983,\n",
       "       4189, 4385, 4499, 4675, 4852, 5042, 5243, 5421, 5549, 5764, 5938,\n",
       "       6159, 6309, 6488, 6629, 6769, 6953, 7112, 7266, 7438, 7593, 7809,\n",
       "       7971, 8169, 8245, 8328, 8382, 8472, 8566, 8682, 8753, 8838, 8908,\n",
       "       8987, 9062, 9157, 9258, 9371, 9530, 9593, 9677, 9803, 9868])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_lengths = [dic[\"video\"].shape[2] for dic in train_data]\n",
    "# make video_lengths entries sum up preceding entries\n",
    "video_lengths = np.cumsum(video_lengths) - 1\n",
    "video_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_frame(indexes):\n",
    "    videos = []\n",
    "    frames = []\n",
    "    for index in indexes:\n",
    "        for i, frame in enumerate(video_lengths):\n",
    "            if index <= frame:\n",
    "                videos.append(i)\n",
    "                if(i == 0):\n",
    "                    frames.append(index)\n",
    "                else:\n",
    "                    frames.append(index - video_lengths[i-1] - 1)\n",
    "                break\n",
    "    return videos, frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos, frames = get_video_frame(test_idx)\n",
    "for i in range(50):\n",
    "    print(\"test idx: \", test_idx[i], \"video: \", videos[i], \"frame: \", frames[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TH = 0.999\n",
    "\n",
    "for i in range(10):\n",
    "    gt =train_data[videos[i]][\"video\"][:,:,frames[i]]\n",
    "    plt.imshow(gt)\n",
    "    plt.show()\n",
    "    first_frame = 255 * pred[i,:,:,0]\n",
    "    first_frame = first_frame > (255 * TH)\n",
    "    plt.imshow(first_frame)\n",
    "    plt.show()\n",
    "\n",
    "# test_frame = 255 * pred[0,:,:,0]\n",
    "# test_frame = test_frame > (255 * TH)\n",
    "# print(test_frame)\n",
    "# plt.imshow(test_frame)\n",
    "# plt.show()\n",
    "\n",
    "# pp = cv2.resize(255 * pred[0,:,:], dsize=train_data[0][\"video\"][0].shape[::-1])\n",
    "# pp = pp > (255 * TH)    \n",
    "# pred_img = im.fromarray(pp)\n",
    "# im\n",
    "# plt.imshow(y_train_box[test_idx][0][:,:,0])\n",
    "# plt.show()\n",
    "# plt.imshow(pred[0][:,:,0])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = model.predict(x_train[test_idx])\n",
    "# pred = np.squeeze(pred)\n",
    "\n",
    "# TH = 0.999\n",
    "# NB_OF_AREAS = 4\n",
    "# intersection = 0\n",
    "# union = 0\n",
    "# fehlt = 0\n",
    "# for i in range(39):\n",
    "#     idx = test_idx[i]\n",
    "#     ff = train_data[idx//3][\"frames\"][idx%3]\n",
    "#     gt = train_data[idx//3][\"label\"][:,:,ff]\n",
    "#     gt_img = im.fromarray(gt)\n",
    "    \n",
    "#     pp = cv2.resize(255 * pred[i,:,:], dsize=gt.shape[::-1])\n",
    "#     pp = pp > (255 * TH)    \n",
    "#     pred_img = im.fromarray(pp)\n",
    "    \n",
    "#     lab = label(pp)\n",
    "#     rps = regionprops(lab)\n",
    "#     area_idx = np.argsort([r.area for r in rps])[::-1]\n",
    "#     new_pp = np.zeros_like(pp)\n",
    "#     for j in area_idx[:NB_OF_AREAS]:\n",
    "#         new_pp[tuple(rps[j].coords.T)] = True\n",
    "#     new_pred_img = im.fromarray(new_pp)\n",
    "    \n",
    "#     fehlt += np.count_nonzero(np.logical_and(gt, np.logical_not(new_pp)))\n",
    "#     intersection += np.count_nonzero(np.logical_and(gt, new_pp))\n",
    "#     union += np.count_nonzero(np.logical_or(gt, new_pp))\n",
    "    \n",
    "# print(fehlt)\n",
    "# print(\"score:\")\n",
    "# print(intersection / union)\n",
    "\n",
    "# #pred = im.fromarray((np.squeeze(model.predict(x_train[16:17]))>0.8))\n",
    "# #gt = im.fromarray(cv2.resize(255 * train_data[5][\"label\"][:,:,51].astype(np.ubyte), dsize=(360, 360)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_train_box[test_idx])\n",
    "pred = np.squeeze(pred)\n",
    "\n",
    "TH = 0.999\n",
    "\n",
    "NB_OF_AREAS = 4\n",
    "intersection = 0\n",
    "union = 0\n",
    "fehlt = 0\n",
    "for i in range(39):\n",
    "    idx = test_idx[i]\n",
    "    ff = train_data[idx//3][\"frames\"][idx%3]\n",
    "    gt = train_data[idx//3][\"label\"][:,:,ff]\n",
    "    gt_img = im.fromarray(gt)\n",
    "    \n",
    "    pp = cv2.resize(255 * pred[i,:,:], dsize=gt.shape[::-1])\n",
    "    pp = pp > (255 * TH)    \n",
    "    pred_img = im.fromarray(pp)\n",
    "    \n",
    "    lab = label(pp)\n",
    "    rps = regionprops(lab)\n",
    "    area_idx = np.argsort([r.area for r in rps])[::-1]\n",
    "    new_pp = np.zeros_like(pp)\n",
    "    for j in area_idx[:NB_OF_AREAS]:\n",
    "        new_pp[tuple(rps[j].coords.T)] = True\n",
    "    new_pred_img = im.fromarray(new_pp)\n",
    "    \n",
    "    fehlt += np.count_nonzero(np.logical_and(gt, np.logical_not(new_pp)))\n",
    "    intersection += np.count_nonzero(np.logical_and(gt, new_pp))\n",
    "    union += np.count_nonzero(np.logical_or(gt, new_pp))\n",
    "    \n",
    "print(fehlt)\n",
    "print(\"score:\")\n",
    "print(intersection / union)\n",
    "\n",
    "# pred = im.fromarray((np.squeeze(model.predict(x_train[16:17]))>0.8))\n",
    "# gt = im.fromarray(cv2.resize(255 * train_data[5][\"label\"][:,:,51].astype(np.ubyte), dsize=(360, 360)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
