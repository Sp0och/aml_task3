{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 15:58:40.911223: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-12 15:58:41.917760: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ts/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-12-12 15:58:41.917820: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-12 15:58:44.119524: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ts/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-12-12 15:58:44.120823: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ts/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-12-12 15:58:44.120867: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "#import os\n",
    "#from PIL import Image as im\n",
    "import cv2\n",
    "#import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import torchdata as td\n",
    "#from torchmetrics.functional import jaccard_index\n",
    "#from tensorflow.keras.utils import to_categorical\n",
    "from PIL import Image as im\n",
    "from skimage.measure import label, regionprops\n",
    "#from sklearn.metrics import f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "#from keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_zipped_pickle(filename):\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        loaded_object = pickle.load(f)\n",
    "        return loaded_object\n",
    "\n",
    "def save_zipped_pickle(obj, filename):\n",
    "    with gzip.open(filename, 'wb') as f:\n",
    "        pickle.dump(obj, f, 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_conv_block_box(x, n_filters):\n",
    "   x = layers.Conv2D(n_filters, 3, padding=\"same\")(x)#kernel_initializer = \"he_normal\"\n",
    "   x = layers.BatchNormalization()(x)\n",
    "   x = layers.ReLU()(x)\n",
    "   x = layers.Conv2D(n_filters, 3, padding=\"same\")(x)#kernel_initializer = \"he_normal\"\n",
    "   x = layers.BatchNormalization()(x)\n",
    "   x = layers.ReLU()(x)\n",
    "   return x\n",
    "\n",
    "def downsample_block_box(x, n_filters):\n",
    "   f = double_conv_block_box(x, n_filters)\n",
    "   p = layers.MaxPool2D(2)(f)\n",
    "   #p = layers.Dropout(0.3)(p)\n",
    "   return f, p\n",
    "\n",
    "def upsample_block_box(x, conv_features, n_filters):\n",
    "   x = layers.Conv2DTranspose(n_filters, 2, 2, padding=\"valid\")(x)\n",
    "   x = layers.concatenate([x, conv_features])\n",
    "   #x = layers.Dropout(0.3)(x)\n",
    "   x = double_conv_block_box(x, n_filters)\n",
    "   return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_box(img_size):\n",
    "    inputs = layers.Input(shape=img_size+(1,))\n",
    "    \n",
    "    f1, p1 = downsample_block_box(inputs, 16)\n",
    "    f2, p2 = downsample_block_box(p1, 32)\n",
    "    f3, p3 = downsample_block_box(p2, 64)\n",
    "    #f4, p4 = downsample_block(p3, 256)\n",
    "    \n",
    "    #bottleneck = double_conv_block(p4, 512)\n",
    "    bottleneck = double_conv_block_box(p3, 128)\n",
    "    \n",
    "    #u6 = upsample_block(bottleneck, f4, 256)\n",
    "    u7 = upsample_block_box(bottleneck, f3, 64)\n",
    "    u8 = upsample_block_box(u7, f2, 32)\n",
    "    u9 = upsample_block_box(u8, f1, 16)\n",
    "\n",
    "    outputs = layers.Conv2D(1, 1, padding=\"valid\", activation = \"sigmoid\")(u9)\n",
    "    \n",
    "    unet_model = tf.keras.Model(inputs, outputs, name=\"U-Net-Box\")\n",
    "    \n",
    "    return unet_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_zipped_pickle(\"train.pkl\")\n",
    "test_data = load_zipped_pickle(\"test.pkl\")\n",
    "samples = load_zipped_pickle(\"sample.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box\n",
    "Videos have different lengths so consider individual images - each with the same box as label - and increase batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate all video frames into one image\n",
    "x_train_box= []\n",
    "y_train_box = []\n",
    "for dic in train_data:\n",
    "    for i in range(dic[\"video\"].shape[2]):\n",
    "        x_train_box.append(cv2.resize(dic[\"video\"][:,:,i], dsize=(256, 256)))\n",
    "        y_train_box.append(cv2.resize(255 * dic[\"box\"].astype(np.ubyte), dsize=(256, 256)))\n",
    "\n",
    "x_train_box = np.expand_dims(np.array(x_train_box, dtype=np.single), 3)\n",
    "y_train_box = np.expand_dims(np.array(y_train_box, dtype=np.single), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9869\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(y_train_box))\n",
    "plt.imshow(y_train_box[0][:,:,0])\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix seed\n",
    "seed = 1\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9869\n",
      "9869\n",
      "------------------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "------------------------------------------------------------------------------------\n",
      "Model: \"U-Net-Box\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 360, 360, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 360, 360, 16  160         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 360, 360, 16  64         ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                   (None, 360, 360, 16  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 360, 360, 16  2320        ['re_lu[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 360, 360, 16  64         ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_1 (ReLU)                 (None, 360, 360, 16  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 180, 180, 16  0           ['re_lu_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 180, 180, 32  4640        ['max_pooling2d[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 180, 180, 32  128        ['conv2d_2[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_2 (ReLU)                 (None, 180, 180, 32  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 180, 180, 32  9248        ['re_lu_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 180, 180, 32  128        ['conv2d_3[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_3 (ReLU)                 (None, 180, 180, 32  0           ['batch_normalization_3[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 90, 90, 32)  0           ['re_lu_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 90, 90, 64)   18496       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 90, 90, 64)  256         ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_4 (ReLU)                 (None, 90, 90, 64)   0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 90, 90, 64)   36928       ['re_lu_4[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 90, 90, 64)  256         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_5 (ReLU)                 (None, 90, 90, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 45, 45, 64)  0           ['re_lu_5[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 45, 45, 128)  73856       ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 45, 45, 128)  512        ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_6 (ReLU)                 (None, 45, 45, 128)  0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 45, 45, 128)  147584      ['re_lu_6[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 45, 45, 128)  512        ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_7 (ReLU)                 (None, 45, 45, 128)  0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 90, 90, 64)  32832       ['re_lu_7[0][0]']                \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 90, 90, 128)  0           ['conv2d_transpose[0][0]',       \n",
      "                                                                  're_lu_5[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 90, 90, 64)   73792       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 90, 90, 64)  256         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_8 (ReLU)                 (None, 90, 90, 64)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 90, 90, 64)   36928       ['re_lu_8[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 90, 90, 64)  256         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_9 (ReLU)                 (None, 90, 90, 64)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 180, 180, 32  8224       ['re_lu_9[0][0]']                \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 180, 180, 64  0           ['conv2d_transpose_1[0][0]',     \n",
      "                                )                                 're_lu_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 180, 180, 32  18464       ['concatenate_1[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 180, 180, 32  128        ['conv2d_10[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_10 (ReLU)                (None, 180, 180, 32  0           ['batch_normalization_10[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 180, 180, 32  9248        ['re_lu_10[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 180, 180, 32  128        ['conv2d_11[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_11 (ReLU)                (None, 180, 180, 32  0           ['batch_normalization_11[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 360, 360, 16  2064       ['re_lu_11[0][0]']               \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 360, 360, 32  0           ['conv2d_transpose_2[0][0]',     \n",
      "                                )                                 're_lu_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 360, 360, 16  4624        ['concatenate_2[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 360, 360, 16  64         ['conv2d_12[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_12 (ReLU)                (None, 360, 360, 16  0           ['batch_normalization_12[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 360, 360, 16  2320        ['re_lu_12[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 360, 360, 16  64         ['conv2d_13[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_13 (ReLU)                (None, 360, 360, 16  0           ['batch_normalization_13[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 360, 360, 1)  17          ['re_lu_13[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 484,561\n",
      "Trainable params: 483,153\n",
      "Non-trainable params: 1,408\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 8\n",
    "BATCH_SIZE = 50\n",
    "fold_no = 0\n",
    "print(len(x_train_box))\n",
    "print(len(y_train_box))\n",
    "for train_idx, test_idx in KFold(n_splits=5, shuffle=True).split(y_train_box):\n",
    "    \n",
    "    fold_no += 1\n",
    "    print('------------------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    print('------------------------------------------------------------------------------------')\n",
    "    \n",
    "    keras.backend.clear_session()\n",
    "    model = get_model_box((360, 360))\n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        #loss=keras.losses.CategoricalCrossentropy(),\n",
    "        loss=keras.losses.BinaryCrossentropy(),\n",
    "        metrics=[keras.metrics.BinaryAccuracy(name='accuracy')]\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        x_train_box[train_idx],\n",
    "        y_train_box[train_idx],\n",
    "        validation_data=(x_train_box[test_idx], y_train_box[test_idx]),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    #scores = model.evaluate(samples[test_idx], labels[test_idx], verbose=0)\n",
    "    #f1 = f1_score(np.argmax(labels[test_idx], axis=1), np.argmax(model.predict(samples[test_idx]), axis=1), average='micro')\n",
    "    #print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%; f1_score of {f1}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_train[test_idx])\n",
    "pred = np.squeeze(pred)\n",
    "\n",
    "TH = 0.999\n",
    "NB_OF_AREAS = 4\n",
    "intersection = 0\n",
    "union = 0\n",
    "fehlt = 0\n",
    "for i in range(39):\n",
    "    idx = test_idx[i]\n",
    "    ff = train_data[idx//3][\"frames\"][idx%3]\n",
    "    gt = train_data[idx//3][\"label\"][:,:,ff]\n",
    "    gt_img = im.fromarray(gt)\n",
    "    \n",
    "    pp = cv2.resize(255 * pred[i,:,:], dsize=gt.shape[::-1])\n",
    "    pp = pp > (255 * TH)    \n",
    "    pred_img = im.fromarray(pp)\n",
    "    \n",
    "    lab = label(pp)\n",
    "    rps = regionprops(lab)\n",
    "    area_idx = np.argsort([r.area for r in rps])[::-1]\n",
    "    new_pp = np.zeros_like(pp)\n",
    "    for j in area_idx[:NB_OF_AREAS]:\n",
    "        new_pp[tuple(rps[j].coords.T)] = True\n",
    "    new_pred_img = im.fromarray(new_pp)\n",
    "    \n",
    "    fehlt += np.count_nonzero(np.logical_and(gt, np.logical_not(new_pp)))\n",
    "    intersection += np.count_nonzero(np.logical_and(gt, new_pp))\n",
    "    union += np.count_nonzero(np.logical_or(gt, new_pp))\n",
    "    \n",
    "print(fehlt)\n",
    "print(\"score:\")\n",
    "print(intersection / union)\n",
    "\n",
    "#pred = im.fromarray((np.squeeze(model.predict(x_train[16:17]))>0.8))\n",
    "#gt = im.fromarray(cv2.resize(255 * train_data[5][\"label\"][:,:,51].astype(np.ubyte), dsize=(360, 360)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
