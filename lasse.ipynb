{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "#import os\n",
    "#from PIL import Image as im\n",
    "import cv2\n",
    "#import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import torchdata as td\n",
    "#from torchmetrics.functional import jaccard_index\n",
    "#from tensorflow.keras.utils import to_categorical\n",
    "from PIL import Image as im\n",
    "from skimage.measure import label, regionprops\n",
    "#from sklearn.metrics import f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "#from keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_zipped_pickle(filename):\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        loaded_object = pickle.load(f)\n",
    "        return loaded_object\n",
    "\n",
    "def save_zipped_pickle(obj, filename):\n",
    "    with gzip.open(filename, 'wb') as f:\n",
    "        pickle.dump(obj, f, 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Read In\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_zipped_pickle(\"train.pkl\")\n",
    "test_data = load_zipped_pickle(\"test.pkl\")\n",
    "sample_data = load_zipped_pickle(\"sample.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max video length is 334 so can add padding to others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "334\n",
      "125\n"
     ]
    }
   ],
   "source": [
    "maximum_train = 0\n",
    "print(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    if(train_data[i][\"video\"].shape[2] > maximum_train):\n",
    "        maximum_train = train_data[i][\"video\"].shape[2]\n",
    "\n",
    "maximum_test = 0\n",
    "for i in range(len(test_data)):\n",
    "    if(test_data[i][\"video\"].shape[2] > maximum_test):\n",
    "        maximum_test = test_data[i][\"video\"].shape[2]\n",
    "\n",
    "\n",
    "print(maximum_train)\n",
    "print(maximum_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amateur:  46\n",
      "expert:  19\n"
     ]
    }
   ],
   "source": [
    "amateur = 0\n",
    "expert = 0\n",
    "for i in range(len(train_data)):\n",
    "    if train_data[i][\"dataset\"] == \"amateur\":\n",
    "        amateur += 1\n",
    "    else:\n",
    "        expert += 1\n",
    "\n",
    "print(\"amateur: \", amateur)\n",
    "print(\"expert: \", expert)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box U-Net\n",
    "### Going for that version 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](Paper_pipeline.png \"TItle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_conv_block_box(x, n_filters):\n",
    "   x = layers.Conv2D(n_filters, 3, padding=\"same\")(x)#kernel_initializer = \"he_normal\"\n",
    "   x = layers.BatchNormalization()(x)\n",
    "   x = layers.ReLU()(x)\n",
    "   x = layers.Conv2D(n_filters, 3, padding=\"same\")(x)#kernel_initializer = \"he_normal\"\n",
    "   x = layers.BatchNormalization()(x)\n",
    "   x = layers.ReLU()(x)\n",
    "   return x\n",
    "\n",
    "def downsample_block_box(x, n_filters):\n",
    "   f = double_conv_block_box(x, n_filters)\n",
    "   p = layers.MaxPool2D(2)(f)\n",
    "   #p = layers.Dropout(0.3)(p)\n",
    "   return f, p\n",
    "\n",
    "def upsample_block_box(x, conv_features, n_filters):\n",
    "   x = layers.Conv2DTranspose(n_filters, 2, 2, padding=\"valid\")(x)\n",
    "   x = layers.concatenate([x, conv_features])\n",
    "   #x = layers.Dropout(0.3)(x)\n",
    "   x = double_conv_block_box(x, n_filters)\n",
    "   return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture: Unet with a LSTM layer between encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(img_size):\n",
    "    inputs = layers.Input(shape=img_size+(1,))\n",
    "    # Make Unet with LSTM layer between encoder and decoder\n",
    "    # Encoder\n",
    "    f1, p1 = downsample_block_box(inputs, 16)\n",
    "    f2, p2 = downsample_block_box(p1, 32)\n",
    "    f3, p3 = downsample_block_box(p2, 64)\n",
    "\n",
    "    # LSTM\n",
    "    b1 = layers.LSTM(128, return_sequences=True)(p3)\n",
    "\n",
    "    # Decoder\n",
    "    u1 = upsample_block_box(b1, f3, 64)\n",
    "    u2 = upsample_block_box(u1, f2, 32)\n",
    "    u3 = upsample_block_box(u2, f1, 16)\n",
    "\n",
    "    # Output\n",
    "    outputs = layers.Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(u3)\n",
    "    model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "### First approach: Videos have different lengths so consider individual images - each with the same box as label - and increase batch size â€“ didn't really work\n",
    "### Second approach: Create an array of image sequences which are fed to the neural network at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second approach\n",
    "x_train_box = []\n",
    "y_train_box = []\n",
    "x_test_box = []\n",
    "\n",
    "for i in range(len(train_data)):\n",
    "    video_array = []\n",
    "    for j in range(train_data[i][\"video\"].shape[2]):\n",
    "        frame = cv2.resize(train_data[i][\"video\"][:,:,j], (256, 256))\n",
    "        video_array.append(frame)\n",
    "    if len(video_array) < 334:\n",
    "        video_array = np.pad(video_array, ((0, 334-len(video_array)), (0, 0), (0, 0)), 'constant')\n",
    "    x_train_box.append(video_array)\n",
    "    y_train_box.append(train_data[i][\"box\"])\n",
    "\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    video_array = []\n",
    "    for j in range(test_data[i][\"video\"].shape[2]):\n",
    "        frame = cv2.resize(test_data[i][\"video\"][:,:,j], (256, 256))\n",
    "        video_array.append(frame)\n",
    "    if len(video_array) < 334:\n",
    "        video_array = np.pad(video_array, ((0, 334-len(video_array)), (0, 0), (0, 0)), 'constant')\n",
    "    x_test_box.append(video_array)\n",
    "\n",
    "x_train_box = np.array(x_train_box, dtype=(\"object\"))\n",
    "y_train_box = np.array(y_train_box, dtype=(\"object\"))\n",
    "x_test_box = np.array(x_test_box, dtype=(\"object\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split training set into training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val_box = x_train_box[52:,:,:,:]\n",
    "x_train_box = x_train_box[:52,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52, 334, 256, 256)\n",
      "(13, 334, 256, 256)\n",
      "(65,)\n",
      "(20, 334, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_box.shape)\n",
    "print(x_val_box.shape)\n",
    "print(y_train_box.shape)\n",
    "print(x_test_box.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deprecated First Approach\n",
    "# # concatenate all video frames into one image\n",
    "# x_train_box= []\n",
    "# y_train_box = []\n",
    "# for dic in train_data:\n",
    "#     for i in range(dic[\"video\"].shape[2]):\n",
    "#         x_train_box.append(cv2.resize(dic[\"video\"][:,:,i], dsize=(256, 256)))\n",
    "#         y_train_box.append(cv2.resize(255 * dic[\"box\"].astype(np.ubyte), dsize=(256, 256)))\n",
    "\n",
    "# x_train_box = np.expand_dims(np.array(x_train_box, dtype=np.single), 3)\n",
    "# y_train_box = np.expand_dims(np.array(y_train_box, dtype=np.single), 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix seed\n",
    "seed = 1\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence lengths:  [334, 177, 195, 181, 211, 209, 129, 179, 168, 151, 113, 214, 151, 166, 210, 118, 177, 171, 258, 173, 190, 109, 206, 196, 114, 176, 177, 190, 201, 178, 128, 215, 174, 221, 150, 179, 141, 140, 184, 159, 154, 172, 155, 216, 162, 198, 76, 83, 54, 90, 94, 116, 71, 85, 70, 79, 75, 95, 101, 113, 159, 63, 84, 126, 65]\n",
      "Sum:  9869\n",
      "expert length:  1186\n",
      "expert percentage:  0.12017428310872429\n",
      "52.0\n"
     ]
    }
   ],
   "source": [
    "sequence_lengths = []\n",
    "for i in range(len(train_data)):\n",
    "    sequence_lengths.append(train_data[i][\"video\"].shape[2])\n",
    "print(\"sequence lengths: \", sequence_lengths)\n",
    "# Sum = np.sum(sequence_lengths)\n",
    "# print(\"Sum: \", Sum)\n",
    "# expert_length = np.sum(sequence_lengths[52:])\n",
    "# print(\"expert length: \", expert_length)\n",
    "# print(\"expert percentage: \", expert_length/Sum)\n",
    "# print(0.8*65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9869\n",
      "9869\n",
      "------------------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "------------------------------------------------------------------------------------\n",
      "Model: \"U-Net-Box\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 256, 256, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 256, 256, 16  160         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 256, 256, 16  64         ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                   (None, 256, 256, 16  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 256, 256, 16  2320        ['re_lu[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 256, 256, 16  64         ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_1 (ReLU)                 (None, 256, 256, 16  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 128, 128, 16  0           ['re_lu_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 128, 128, 32  4640        ['max_pooling2d[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 128, 128, 32  128        ['conv2d_2[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_2 (ReLU)                 (None, 128, 128, 32  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 128, 128, 32  9248        ['re_lu_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 128, 128, 32  128        ['conv2d_3[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_3 (ReLU)                 (None, 128, 128, 32  0           ['batch_normalization_3[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 32)  0           ['re_lu_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 64, 64, 64)   18496       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 64, 64, 64)  256         ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_4 (ReLU)                 (None, 64, 64, 64)   0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 64, 64, 64)   36928       ['re_lu_4[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 64, 64, 64)  256         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_5 (ReLU)                 (None, 64, 64, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 64)  0           ['re_lu_5[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 32, 32, 128)  73856       ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 32, 32, 128)  512        ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_6 (ReLU)                 (None, 32, 32, 128)  0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 32, 32, 128)  147584      ['re_lu_6[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 32, 32, 128)  512        ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_7 (ReLU)                 (None, 32, 32, 128)  0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 64, 64, 64)  32832       ['re_lu_7[0][0]']                \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 64, 64, 128)  0           ['conv2d_transpose[0][0]',       \n",
      "                                                                  're_lu_5[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 64, 64, 64)   73792       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 64, 64, 64)  256         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_8 (ReLU)                 (None, 64, 64, 64)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 64, 64, 64)   36928       ['re_lu_8[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 64, 64, 64)  256         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_9 (ReLU)                 (None, 64, 64, 64)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 128, 128, 32  8224       ['re_lu_9[0][0]']                \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 128, 128, 64  0           ['conv2d_transpose_1[0][0]',     \n",
      "                                )                                 're_lu_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 128, 128, 32  18464       ['concatenate_1[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 128, 128, 32  128        ['conv2d_10[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_10 (ReLU)                (None, 128, 128, 32  0           ['batch_normalization_10[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 128, 128, 32  9248        ['re_lu_10[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 128, 128, 32  128        ['conv2d_11[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_11 (ReLU)                (None, 128, 128, 32  0           ['batch_normalization_11[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 256, 256, 16  2064       ['re_lu_11[0][0]']               \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 256, 256, 32  0           ['conv2d_transpose_2[0][0]',     \n",
      "                                )                                 're_lu_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 256, 256, 16  4624        ['concatenate_2[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 256, 256, 16  64         ['conv2d_12[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_12 (ReLU)                (None, 256, 256, 16  0           ['batch_normalization_12[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 256, 256, 16  2320        ['re_lu_12[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 256, 256, 16  64         ['conv2d_13[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_13 (ReLU)                (None, 256, 256, 16  0           ['batch_normalization_13[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 256, 256, 1)  17          ['re_lu_13[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 484,561\n",
      "Trainable params: 483,153\n",
      "Non-trainable params: 1,408\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/8\n",
      "158/158 - 1239s - loss: -2.0223e+02 - accuracy: 0.7157 - val_loss: 0.3200 - val_accuracy: 0.7355 - 1239s/epoch - 8s/step\n",
      "Epoch 2/8\n",
      "158/158 - 1201s - loss: -4.4243e+02 - accuracy: 0.5390 - val_loss: -2.7493e+02 - val_accuracy: 0.6711 - 1201s/epoch - 8s/step\n",
      "Epoch 3/8\n",
      "158/158 - 1124s - loss: -7.6179e+02 - accuracy: 0.5311 - val_loss: -6.6430e+02 - val_accuracy: 0.5517 - 1124s/epoch - 7s/step\n",
      "Epoch 4/8\n",
      "158/158 - 1136s - loss: -1.1761e+03 - accuracy: 0.3162 - val_loss: -1.0903e+03 - val_accuracy: 0.3271 - 1136s/epoch - 7s/step\n",
      "Epoch 5/8\n",
      "158/158 - 1121s - loss: -1.6927e+03 - accuracy: 0.0162 - val_loss: -1.6363e+03 - val_accuracy: 7.4503e-04 - 1121s/epoch - 7s/step\n",
      "Epoch 6/8\n",
      "158/158 - 1126s - loss: -2.3030e+03 - accuracy: 0.0015 - val_loss: -2.4725e+03 - val_accuracy: 4.3107e-04 - 1126s/epoch - 7s/step\n",
      "Epoch 7/8\n",
      "158/158 - 1134s - loss: -3.0035e+03 - accuracy: 0.0058 - val_loss: -3.3445e+03 - val_accuracy: 4.2916e-05 - 1134s/epoch - 7s/step\n",
      "Epoch 8/8\n",
      "158/158 - 1114s - loss: -3.7997e+03 - accuracy: 0.0155 - val_loss: -4.2478e+03 - val_accuracy: 2.5756e-04 - 1114s/epoch - 7s/step\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 8\n",
    "BATCH_SIZE = 50\n",
    "fold_no = 0\n",
    "print(len(x_train_box))\n",
    "print(len(y_train_box))\n",
    "for train_idx, test_idx in KFold(n_splits=5, shuffle=True).split(y_train_box):\n",
    "    \n",
    "    fold_no += 1\n",
    "    print('------------------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    print('------------------------------------------------------------------------------------')\n",
    "    \n",
    "    keras.backend.clear_session()\n",
    "    model = get_model_box((256, 256))\n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        #loss=keras.losses.CategoricalCrossentropy(),\n",
    "        loss=keras.losses.BinaryCrossentropy(),\n",
    "        metrics=[keras.metrics.BinaryAccuracy(name='accuracy')]\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        x_train_box[train_idx],\n",
    "        y_train_box[train_idx],\n",
    "        validation_data=(x_train_box[test_idx], y_train_box[test_idx]),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    #scores = model.evaluate(samples[test_idx], labels[test_idx], verbose=0)\n",
    "    #f1 = f1_score(np.argmax(labels[test_idx], axis=1), np.argmax(model.predict(samples[test_idx]), axis=1), average='micro')\n",
    "    #print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%; f1_score of {f1}')\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_box.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model if already trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model_box.h5\n",
    "# model = tf.keras.models.load_model(\"model_box.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 54s 870ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1974, 256, 256, 1)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(x_train_box[test_idx])\n",
    "x_train_box[test_idx].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get The video lenghts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 333,  510,  705,  886, 1097, 1306, 1435, 1614, 1782, 1933, 2046,\n",
       "       2260, 2411, 2577, 2787, 2905, 3082, 3253, 3511, 3684, 3874, 3983,\n",
       "       4189, 4385, 4499, 4675, 4852, 5042, 5243, 5421, 5549, 5764, 5938,\n",
       "       6159, 6309, 6488, 6629, 6769, 6953, 7112, 7266, 7438, 7593, 7809,\n",
       "       7971, 8169, 8245, 8328, 8382, 8472, 8566, 8682, 8753, 8838, 8908,\n",
       "       8987, 9062, 9157, 9258, 9371, 9530, 9593, 9677, 9803, 9868])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_lengths = [dic[\"video\"].shape[2] for dic in train_data]\n",
    "# make video_lengths entries sum up preceding entries\n",
    "video_lengths = np.cumsum(video_lengths) - 1\n",
    "video_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_frame(indexes):\n",
    "    videos = []\n",
    "    frames = []\n",
    "    for index in indexes:\n",
    "        for i, frame in enumerate(video_lengths):\n",
    "            if index <= frame:\n",
    "                videos.append(i)\n",
    "                if(i == 0):\n",
    "                    frames.append(index)\n",
    "                else:\n",
    "                    frames.append(index - video_lengths[i-1] - 1)\n",
    "                break\n",
    "    return videos, frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos, frames = get_video_frame(test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TH = 0.999\n",
    "\n",
    "for i in range(10):\n",
    "    gt =train_data[videos[i]][\"video\"][:,:,frames[i]]\n",
    "    plt.imshow(gt)\n",
    "    plt.show()\n",
    "    first_frame = 255 * pred[i,:,:,0]\n",
    "    first_frame = first_frame > (255 * TH)\n",
    "    plt.imshow(first_frame)\n",
    "    plt.show()\n",
    "\n",
    "# test_frame = 255 * pred[0,:,:,0]\n",
    "# test_frame = test_frame > (255 * TH)\n",
    "# print(test_frame)\n",
    "# plt.imshow(test_frame)\n",
    "# plt.show()\n",
    "\n",
    "# pp = cv2.resize(255 * pred[0,:,:], dsize=train_data[0][\"video\"][0].shape[::-1])\n",
    "# pp = pp > (255 * TH)    \n",
    "# pred_img = im.fromarray(pp)\n",
    "# im\n",
    "# plt.imshow(y_train_box[test_idx][0][:,:,0])\n",
    "# plt.show()\n",
    "# plt.imshow(pred[0][:,:,0])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_train_box[test_idx])\n",
    "pred = np.squeeze(pred)\n",
    "\n",
    "TH = 0.999\n",
    "\n",
    "NB_OF_AREAS = 4\n",
    "intersection = 0\n",
    "union = 0\n",
    "fehlt = 0\n",
    "for i in range(39):\n",
    "    idx = test_idx[i]\n",
    "    ff = train_data[idx//3][\"frames\"][idx%3]\n",
    "    gt = train_data[idx//3][\"label\"][:,:,ff]\n",
    "    gt_img = im.fromarray(gt)\n",
    "    \n",
    "    pp = cv2.resize(255 * pred[i,:,:], dsize=gt.shape[::-1])\n",
    "    pp = pp > (255 * TH)    \n",
    "    pred_img = im.fromarray(pp)\n",
    "    \n",
    "    lab = label(pp)\n",
    "    rps = regionprops(lab)\n",
    "    area_idx = np.argsort([r.area for r in rps])[::-1]\n",
    "    new_pp = np.zeros_like(pp)\n",
    "    for j in area_idx[:NB_OF_AREAS]:\n",
    "        new_pp[tuple(rps[j].coords.T)] = True\n",
    "    new_pred_img = im.fromarray(new_pp)\n",
    "    \n",
    "    fehlt += np.count_nonzero(np.logical_and(gt, np.logical_not(new_pp)))\n",
    "    intersection += np.count_nonzero(np.logical_and(gt, new_pp))\n",
    "    union += np.count_nonzero(np.logical_or(gt, new_pp))\n",
    "    \n",
    "print(fehlt)\n",
    "print(\"score:\")\n",
    "print(intersection / union)\n",
    "\n",
    "# pred = im.fromarray((np.squeeze(model.predict(x_train[16:17]))>0.8))\n",
    "# gt = im.fromarray(cv2.resize(255 * train_data[5][\"label\"][:,:,51].astype(np.ubyte), dsize=(360, 360)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
