{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import cv2 as cv\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from PIL import Image as im\n",
    "from skimage.measure import label, regionprops\n",
    "from scipy.ndimage import median_filter\n",
    "# import canny edge detector\n",
    "from skimage.feature import canny\n",
    "from scipy.ndimage import binary_erosion, binary_dilation, binary_closing, binary_opening, center_of_mass, fourier_ellipsoid, generate_binary_structure"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_augmentations = 10\n",
    "EPOCHS = 32\n",
    "BATCH_SIZE = 8\n",
    "INPUT_SHAPE = (360, 360)\n",
    "SUBMISSION = True\n",
    "TH = 0.5\n",
    "NB_OF_AREAS = 3\n",
    "EROSION_ITERATIONS = 5\n",
    "MODEL_FILE = 'model.hdf5'\n",
    "BEST_MODEL_FILE = 'best_model.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_zipped_pickle(filename):\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        loaded_object = pickle.load(f)\n",
    "        return loaded_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_zipped_pickle(obj, filename):\n",
    "    with gzip.open(filename, 'wb') as f:\n",
    "        pickle.dump(obj, f, 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_data = load_zipped_pickle(\"train.pkl\")\n",
    "test_data = load_zipped_pickle(\"test.pkl\")\n",
    "samples = load_zipped_pickle(\"sample.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datagen = ImageDataGenerator(horizontal_flip=True,\n",
    "                    rotation_range=10,\n",
    "                    shear_range=10,\n",
    "                    zoom_range=[0.8, 1.1],\n",
    "                    height_shift_range=0.1,\n",
    "                    width_shift_range=0.1,\n",
    "                    brightness_range=(0.3, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(image, mask):\n",
    "    seed = 1\n",
    "    data_gen_args = dict(horizontal_flip=True,\n",
    "                         rotation_range=10,\n",
    "                         shear_range=10,\n",
    "                         zoom_range=[0.8, 1.1],\n",
    "                         height_shift_range=0.1,\n",
    "                         width_shift_range=0.1,\n",
    "                         brightness_range=(0.3, 1))\n",
    "\n",
    "    frame_augmentor = ImageDataGenerator(**data_gen_args)\n",
    "    label_augmentor = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "    myimg = image.reshape((1,) + image.shape + (1,))\n",
    "    mask = mask.reshape((1,) + mask.shape + (1,))\n",
    "\n",
    "    aug_frames = frame_augmentor.flow(myimg, seed=seed, batch_size=1)\n",
    "    aug_labels = label_augmentor.flow(mask, seed=seed, batch_size=1)\n",
    "\n",
    "\n",
    "    return aug_frames, aug_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    X_val=None,\n",
    "    Y_val=None,\n",
    "    nr_augmentations=1,\n",
    "    data_gen_args=dict(\n",
    "        #horizontal_flip=True,\n",
    "        #rotation_range=10,\n",
    "        #zoom_range=0.1,\n",
    "        #height_shift_range=0.1,\n",
    "        #width_shift_range=0.1,\n",
    "        fill_mode='constant'\n",
    "        \n",
    "        # vertical_flip=False,\n",
    "        # shear_range=10,\n",
    "        # zoom_range=[0.8, 1.1],\n",
    "        # brightness_range=(0.3, 1)\n",
    "    )\n",
    "):\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    if(X_val is not None and Y_val is not None):\n",
    "        x_val = []\n",
    "        y_val = []\n",
    "\n",
    "    X_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    Y_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    X_datagen.fit(X_train, augment=True, seed=0)\n",
    "    Y_datagen.fit(Y_train, augment=True, seed=0)\n",
    "    X_train_augmented = X_datagen.flow(X_train, batch_size=BATCH_SIZE, shuffle=True, seed=0)\n",
    "    Y_train_augmented = Y_datagen.flow(Y_train, batch_size=BATCH_SIZE, shuffle=True, seed=0)\n",
    "\n",
    "    if not (X_val is None) and not (Y_val is None):\n",
    "        X_datagen_val = ImageDataGenerator(**data_gen_args)\n",
    "        Y_datagen_val = ImageDataGenerator(**data_gen_args)\n",
    "        X_datagen_val.fit(X_val, augment=False, seed=0)\n",
    "        Y_datagen_val.fit(Y_val, augment=False, seed=0)\n",
    "        X_val_augmented = X_datagen_val.flow(X_val, batch_size=BATCH_SIZE, shuffle=False, seed=0)\n",
    "        Y_val_augmented = Y_datagen_val.flow(Y_val, batch_size=BATCH_SIZE, shuffle=False, seed=0)\n",
    "\n",
    "    #     return zip(X_train_augmented, Y_train_augmented), zip(X_val_augmented, Y_val_augmented)\n",
    "    # else:\n",
    "    #     return zip(X_train_augmented, Y_train_augmented), None\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of augmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample_id = 50\n",
    "labeled_frame_idx = 1\n",
    "\n",
    "video = np.copy(train_data[train_sample_id]['video'])\n",
    "labels = train_data[train_sample_id]['label']\n",
    "box = train_data[train_sample_id]['box']\n",
    "labeled_frames = train_data[train_sample_id]['frames']\n",
    "\n",
    "aug_frames, aug_labels = augment_data(video[:,:,labeled_frames[labeled_frame_idx]], 255*labels[:,:,labeled_frames[labeled_frame_idx]].astype(np.ubyte))\n",
    "\n",
    "nrow = 4\n",
    "ncol = 4\n",
    "# generate samples and plot\n",
    "fig, ax = plt.subplots(nrows=nrow, ncols=ncol, figsize=(15, 15 * nrow / ncol))\n",
    "\n",
    "for ox in ax.reshape(-1):\n",
    "    # convert to unsigned integers\n",
    "    image = next(aug_frames)[0].astype('uint8')\n",
    "    mask = next(aug_labels)[0].astype('uint8')\n",
    "    ox.imshow(image)\n",
    "    ox.imshow(mask, alpha=0.5)\n",
    "    ox.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input image with augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "for d in train_data:\n",
    "    for i in d[\"frames\"]:\n",
    "        image = d[\"video\"][:, :, i]\n",
    "        mask = 255 * d[\"label\"][:, :, i].astype(np.ubyte)\n",
    "        x_train.append(cv2.resize(image, dsize=(360, 360)))\n",
    "        y_train.append(cv2.resize(mask, dsize=(360, 360)))\n",
    "        aug_images, aug_masks = augment_data(image, mask)\n",
    "        for tt in range(n_augmentations):\n",
    "            x_train.append(cv2.resize(next(aug_images)[0], dsize=(360, 360)))\n",
    "            y_train.append(cv2.resize(next(aug_masks)[0], dsize=(360, 360)))\n",
    "\n",
    "x_test = []\n",
    "for d in test_data:\n",
    "    for i in range(d[\"video\"].shape[2]):\n",
    "        x_test.append(cv2.resize(d[\"video\"][:, :, i], dsize=(360, 360)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.expand_dims(np.array(x_train, dtype=np.single), 3)\n",
    "y_train = np.expand_dims(np.array(y_train, dtype=np.single), 3)\n",
    "x_test = np.expand_dims(np.array(x_test, dtype=np.single), 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Median Filter Smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_median_filtered = []\n",
    "x_test_median_filtered = []\n",
    "for i in range(x_train.shape[0]):\n",
    "    x_train_median_filtered.append(median_filter(x_train[i,:,:,0], size=3))\n",
    "for i in range(x_test.shape[0]):\n",
    "    x_test_median_filtered.append(median_filter(x_test[i,:,:,0], size=3))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Canny Edges Extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_canny_edges = []\n",
    "x_test_canny_edges = []\n",
    "for i in range(x_train.shape[0]):\n",
    "    x_train_canny_edges.append(canny(x_train[i,:,:,0], sigma=3))\n",
    "\n",
    "for i in range(x_test.shape[0]):\n",
    "    x_test_canny_edges.append(canny(x_test[i,:,:,0], sigma=3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview of image channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x_train))\n",
    "print(x_train[0].shape)\n",
    "print(len(x_train_median_filtered))\n",
    "print(x_train_median_filtered[0].shape)\n",
    "print(len(x_train_canny_edges))\n",
    "print(x_train_canny_edges[0].shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the median filtered images and the canny edges to the x_train and x_test arrays\n",
    "x_train = np.concatenate((x_train, np.expand_dims(np.array(x_train_median_filtered, dtype=np.single), 3)), axis=3)\n",
    "x_train = np.concatenate((x_train, np.expand_dims(np.array(x_train_canny_edges, dtype=np.single), 3)), axis=3)\n",
    "\n",
    "x_test = np.concatenate((x_test, np.expand_dims(np.array(x_test_median_filtered, dtype=np.single), 3)), axis=3)\n",
    "x_test = np.concatenate((x_test, np.expand_dims(np.array(x_test_canny_edges, dtype=np.single), 3)), axis=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Input data to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train images shape: \", x_train.shape)\n",
    "print(\"train labels shape: \", y_train.shape)\n",
    "print(\"test images shape: \", x_test.shape)\n",
    "# almost the same number for the test images as we consider not only keyframes but have no data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index = np.random.randint(0, x_train.shape[0])\n",
    "# make subplot of the 3 image channels with overlayed mask\n",
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15, 15))\n",
    "ax[0].imshow(x_train[random_index,:,:,0], cmap='gray')\n",
    "ax[0].imshow(y_train[random_index,:,:,0], cmap='gray', alpha=0.5)\n",
    "ax[1].imshow(x_train[random_index,:,:,1], cmap='gray')\n",
    "ax[1].imshow(y_train[random_index,:,:,0], cmap='gray', alpha=0.5)\n",
    "ax[2].imshow(x_train[random_index,:,:,2], cmap='gray')\n",
    "ax[2].imshow(y_train[random_index,:,:,0], cmap='gray', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual Train / Validation Split (80/20 = 52/13) making sure that only expert data is in validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training data into training and validation sets 80/20\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_conv_block(x, n_filters):\n",
    "   x = layers.Conv2D(n_filters, 3, padding=\"same\")(x)#kernel_initializer = \"he_normal\"\n",
    "   x = layers.BatchNormalization()(x)\n",
    "   x = layers.ReLU()(x)\n",
    "   x = layers.Conv2D(n_filters, 3, padding=\"same\")(x)#kernel_initializer = \"he_normal\"\n",
    "   x = layers.BatchNormalization()(x)\n",
    "   x = layers.ReLU()(x)\n",
    "   return x\n",
    "\n",
    "def downsample_block(x, n_filters):\n",
    "   f = double_conv_block(x, n_filters)\n",
    "   p = layers.MaxPool2D(2)(f)\n",
    "   #p = layers.Dropout(0.3)(p)\n",
    "   return f, p\n",
    "\n",
    "def upsample_block(x, conv_features, n_filters):\n",
    "   x = layers.Conv2DTranspose(n_filters, 2, 2, padding=\"valid\")(x)\n",
    "   x = layers.concatenate([x, conv_features])\n",
    "   #x = layers.Dropout(0.3)(x)\n",
    "   x = double_conv_block(x, n_filters)\n",
    "   return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(img_size):\n",
    "    inputs = layers.Input(shape=(img_size, img_size, 3))\n",
    "    \n",
    "    f1, p1 = downsample_block(inputs, 16)\n",
    "    f2, p2 = downsample_block(p1, 32)\n",
    "    f3, p3 = downsample_block(p2, 64)\n",
    "    #f4, p4 = downsample_block(p3, 256)\n",
    "    \n",
    "    #bottleneck = double_conv_block(p4, 512)\n",
    "    bottleneck = double_conv_block(p3, 128)\n",
    "    \n",
    "    #u6 = upsample_block(bottleneck, f4, 256)\n",
    "    u7 = upsample_block(bottleneck, f3, 64)\n",
    "    u8 = upsample_block(u7, f2, 32)\n",
    "    u9 = upsample_block(u8, f1, 16)\n",
    "\n",
    "    outputs = layers.Conv2D(1, 1, padding=\"valid\", activation = \"sigmoid\")(u9)\n",
    "    \n",
    "    unet_model = tf.keras.Model(inputs, outputs, name=\"U-Net\")\n",
    "    \n",
    "    return unet_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix seed\n",
    "seed = 1\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit model once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "EPOCHS = [8,8,8,8,8]\n",
    "BATCH_SIZES = [4,4,4,4,4]\n",
    "NR_OF_AUGMENTATIONS = [20,20,20,20,20]\n",
    "LEARNING_RATES = [1e-3,1e-3,1e-3,1e-3,1e-3]\n",
    "LOSS_FUNCTIONS = [keras.losses.BinaryCrossentropy(),keras.losses.BinaryCrossentropy(),keras.losses.BinaryCrossentropy(),keras.losses.BinaryCrossentropy(),keras.losses.BinaryCrossentropy()]\n",
    "print('------------------------------------------------------------------------------------')\n",
    "print(f'Training for fold {0  + 1} ...')\n",
    "print(f'BATCH_SIZE: {BATCH_SIZES[0]}')\n",
    "print(f'EPOCHS: {EPOCHS[0]}')\n",
    "print(f'nr_of_augmentations: {NR_OF_AUGMENTATIONS[0]}')\n",
    "print(f'learning_rate: {LEARNING_RATES[0]}')\n",
    "print(f'loss_function: {LOSS_FUNCTIONS[0]}')\n",
    "print('------------------------------------------------------------------------------------')\n",
    "\n",
    "keras.backend.clear_session()\n",
    "model = get_model(360)\n",
    "model.summary()\n",
    "print(model.output_shape)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATES[0]),\n",
    "    #loss=keras.losses.CategoricalCrossentropy(),\n",
    "    loss=LOSS_FUNCTIONS[0],\n",
    "    metrics=[keras.metrics.BinaryAccuracy(name='accuracy')]\n",
    ")\n",
    "# Fit the model with augmented data\n",
    "model.fit(x_train, y_train,\n",
    "        validation_data=(x_val, y_val),\n",
    "        batch_size=BATCH_SIZES[0],\n",
    "        epochs=EPOCHS[0],\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    #scores = model.evaluate(samples[test_idx], labels[test_idx], verbose=0)\n",
    "    #f1 = f1_score(np.argmax(labels[test_idx], axis=1), np.argmax(model.predict(samples[test_idx]), axis=1), average='micro')\n",
    "    #print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%; f1_score of {f1}')\n",
    "    # break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save('triple_input_model')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper Param Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "EPOCHS = [8,8,8,8,8]\n",
    "BATCH_SIZES = [4,4,4,4,4]\n",
    "NR_OF_AUGMENTATIONS = [0,5,10,15,20]\n",
    "LEARNING_RATES = [1e-3,1e-3,1e-3,1e-3,1e-3]\n",
    "LOSS_FUNCTIONS = [keras.losses.BinaryCrossentropy(),keras.losses.BinaryCrossentropy(),keras.losses.BinaryCrossentropy(),keras.losses.BinaryCrossentropy(),keras.losses.BinaryCrossentropy()]\n",
    "for fold_nr in range(5):\n",
    "    print('------------------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_nr  + 1} ...')\n",
    "    print(f'BATCH_SIZE: {BATCH_SIZES[fold_nr]}')\n",
    "    print(f'EPOCHS: {EPOCHS[fold_nr]}')\n",
    "    print(f'nr_of_augmentations: {NR_OF_AUGMENTATIONS[fold_nr]}')\n",
    "    print(f'learning_rate: {LEARNING_RATES[fold_nr]}')\n",
    "    print(f'loss_function: {LOSS_FUNCTIONS[fold_nr]}')\n",
    "    print('------------------------------------------------------------------------------------')\n",
    "\n",
    "    keras.backend.clear_session()\n",
    "    model = get_model(256)\n",
    "    model.summary()\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.compile(\n",
    "      optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATES[fold_nr]),\n",
    "      #loss=keras.losses.CategoricalCrossentropy(),\n",
    "      loss=LOSS_FUNCTIONS[0],\n",
    "      metrics=[keras.metrics.BinaryAccuracy(name='accuracy')]\n",
    "    )\n",
    "# Fit the model with augmented data\n",
    "    model.fit(datagen.flow(x_train, y=y_train, batch_size=NR_OF_AUGMENTATIONS[fold_nr], seed=seed, shuffle=False),\n",
    "            validation_data=(x_val, y_val),\n",
    "            batch_size=BATCH_SIZES[fold_nr],\n",
    "            epochs=EPOCHS[fold_nr],\n",
    "            verbose=2\n",
    "        )\n",
    "\n",
    "    #scores = model.evaluate(samples[test_idx], labels[test_idx], verbose=0)\n",
    "    #f1 = f1_score(np.argmax(labels[test_idx], axis=1), np.argmax(model.predict(samples[test_idx]), axis=1), average='micro')\n",
    "    #print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%; f1_score of {f1}')\n",
    "    # break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('three_channel_segmentation_model_15_augm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = tf.keras.models.load_model('three_channel_segmentation_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indexes = []\n",
    "for d in test_data:\n",
    "    test_indexes.append(d[\"video\"].shape[0])\n",
    "\n",
    "test_indexes = np.cumsum(test_indexes)\n",
    "print(test_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split predictions into videos\n",
    "predictions_per_video = np.split(predictions, test_indexes[:-1], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_squeezed = np.squeeze(predictions_per_video)\n",
    "test = np.array(np.zeros_like(predictions_per_video[0][0]), dtype=bool)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros(INPUT_SHAPE)\n",
    "for d in train_data:\n",
    "    for i in d[\"frames\"]:\n",
    "        x = cv2.resize(d[\"video\"][:,:,i], dsize=INPUT_SHAPE[:2])\n",
    "        y = cv2.resize(255 * d[\"label\"][:,:,i].astype(np.ubyte), dsize=INPUT_SHAPE[:2])\n",
    "        mask = np.logical_or(mask, y)\n",
    "\n",
    "mask = cv2.morphologyEx(255 * mask.astype(np.ubyte), cv2.MORPH_OPEN, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (50, 50)))\n",
    "mask = binary_dilation(mask, iterations=10)\n",
    "\n",
    "test = np.array(np.zeros_like(predictions_per_video[0]), dtype=bool)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = load_zipped_pickle(\"sample.pkl\")\n",
    "print(samples[0][\"prediction\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionn = load_zipped_pickle(\"my_predictions.pkl\")\n",
    "print(predictionn[0][\"prediction\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_pp = []\n",
    "for video in predictions_per_video:\n",
    "    prediction = np.array(np.zeros_like(video), dtype=bool)\n",
    "    for frame in video:\n",
    "        # threshold filtering and filter out when outside of expected location\n",
    "        print(prediction.shape)\n",
    "        pp = cv2.resize(255 * frame, dsize=prediction.shape[::-1][1:])\n",
    "        pp = pp > (255 * TH)\n",
    "        pp = np.logical_and(cv2.resize(mask.astype(np.ubyte), dsize=prediction.shape[::-1][1:]), pp)\n",
    "        # pred_img = im.fromarray(pp)\n",
    "    \n",
    "        lab = label(pp)\n",
    "        rps = regionprops(lab)\n",
    "        area_idx = np.argsort([r.area for r in rps])[::-1]\n",
    "        new_pp = np.zeros_like(pp)\n",
    "        for j in area_idx[:NB_OF_AREAS]:\n",
    "            new_pp[tuple(rps[j].coords.T)] = True\n",
    "        #new_pp = binary_erosion(new_pp, iterations=EROSION_ITERATIONS)\n",
    "        new_pred_img = im.fromarray(new_pp)\n",
    "        \n",
    "        prediction[:,:,i] = new_pp\n",
    "    \n",
    "    predictions_pp.append({'name': d['name'], 'prediction': prediction})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    random_index = np.random.randint(0, len(x_train))\n",
    "    enhanced = 255 * train_predictions[random_index,:,:,0]\n",
    "    enhanced = enhanced > 255 * 0.99\n",
    "    # Create a horizontal subplot of xtrain image, ytrain image and enhanced image\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 15))\n",
    "    axs[0].imshow(x_train[random_index,:,:,0])\n",
    "    axs[0].set_title('x_train')\n",
    "    axs[1].imshow(y_train[random_index,:,:,0])\n",
    "    axs[1].set_title('y_train')\n",
    "    axs[2].imshow(enhanced, cmap='gray')\n",
    "    axs[2].set_title('enhanced')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    random_index = np.random.randint(0, len(x_test))\n",
    "    enhanced = 255 * predictions[random_index,:,:,0]\n",
    "    enhanced = enhanced > 255 * 0.99\n",
    "    # Create a horizontal subplot of the two images x_test and enhanced\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 10))\n",
    "    axs[0].imshow(x_test[random_index,:,:,0])\n",
    "    axs[0].set_title('x_test')\n",
    "    axs[1].imshow(enhanced, cmap='gray')\n",
    "    axs[1].set_title('enhanced')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "model = tf.keras.models.load_model('triple_input_model')\n",
    "for d in test_data:\n",
    "    \n",
    "    x_test = []\n",
    "    for i in range(d[\"video\"].shape[2]):\n",
    "        x_test.append(cv2.resize(d[\"video\"][:,:,i], dsize=INPUT_SHAPE))\n",
    "    x_test = np.expand_dims(np.array(x_test, dtype=np.single), 3)\n",
    "\n",
    "    x_train_median_filtered = []\n",
    "    x_test_median_filtered = []\n",
    "    for i in range(x_train.shape[0]):\n",
    "        x_train_median_filtered.append(median_filter(x_train[i,:,:,0], size=3))\n",
    "    for i in range(x_test.shape[0]):\n",
    "        x_test_median_filtered.append(median_filter(x_test[i,:,:,0], size=3))\n",
    "        x_train_canny_edges = []\n",
    "    x_test_canny_edges = []\n",
    "    for i in range(x_train.shape[0]):\n",
    "        x_train_canny_edges.append(canny(x_train[i,:,:,0], sigma=3))\n",
    "\n",
    "    for i in range(x_test.shape[0]):\n",
    "        x_test_canny_edges.append(canny(x_test[i,:,:,0], sigma=3))\n",
    "    x_test = np.concatenate((x_test, np.expand_dims(np.array(x_test_median_filtered, dtype=np.single), 3)), axis=3)\n",
    "    x_test = np.concatenate((x_test, np.expand_dims(np.array(x_test_canny_edges, dtype=np.single), 3)), axis=3)\n",
    "\n",
    "    \n",
    "    pred = model.predict(x_test)\n",
    "    pred = np.squeeze(pred)\n",
    "    \n",
    "    prediction = np.array(np.zeros_like(d['video']), dtype=bool)\n",
    "    print(prediction.shape)\n",
    "    \n",
    "    for i in range(pred.shape[0]):\n",
    "        \n",
    "        pp = cv2.resize(255 * pred[i,:,:], dsize=prediction.shape[::-1][1:])\n",
    "        pp = pp > (255 * TH)\n",
    "        pp = np.logical_and(cv2.resize(mask.astype(np.ubyte), dsize=prediction.shape[::-1][1:]), pp)\n",
    "        pred_img = im.fromarray(pp)\n",
    "        \n",
    "        lab = label(pp)\n",
    "        rps = regionprops(lab)\n",
    "        area_idx = np.argsort([r.area for r in rps])[::-1]\n",
    "        new_pp = np.zeros_like(pp)\n",
    "        for j in area_idx[:NB_OF_AREAS]:\n",
    "            new_pp[tuple(rps[j].coords.T)] = True\n",
    "        #new_pp = binary_erosion(new_pp, iterations=EROSION_ITERATIONS)\n",
    "        new_pred_img = im.fromarray(new_pp)\n",
    "        \n",
    "        prediction[:,:,i] = new_pp\n",
    "    \n",
    "    predictions.append({'name': d['name'], 'prediction': prediction})\n",
    "\n",
    "save_zipped_pickle(predictions, 'my_predictions.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array([1,2] + [3,4])\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 1,  4,  5,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22,\n",
      "       24, 25, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42,\n",
      "       43, 44]), array([ 0,  2,  3,  6, 19, 20, 23, 26, 34, 45]))\n",
      "(array([ 0,  1,  2,  3,  4,  5,  6,  8,  9, 10, 11, 12, 13, 14, 16, 18, 19,\n",
      "       20, 22, 23, 24, 25, 26, 28, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41,\n",
      "       42, 44, 45]), array([ 7, 15, 17, 21, 27, 29, 37, 38, 43]))\n",
      "(array([ 0,  2,  3,  5,  6,  7,  8, 11, 13, 14, 15, 16, 17, 19, 20, 21, 22,\n",
      "       23, 24, 25, 26, 27, 28, 29, 30, 33, 34, 35, 36, 37, 38, 39, 40, 42,\n",
      "       43, 44, 45]), array([ 1,  4,  9, 10, 12, 18, 31, 32, 41]))\n",
      "(array([ 0,  1,  2,  3,  4,  6,  7,  8,  9, 10, 11, 12, 15, 16, 17, 18, 19,\n",
      "       20, 21, 23, 24, 26, 27, 29, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42,\n",
      "       43, 44, 45]), array([ 5, 13, 14, 22, 25, 28, 30, 35, 39]))\n",
      "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  9, 10, 12, 13, 14, 15, 17, 18, 19,\n",
      "       20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 37, 38, 39,\n",
      "       41, 43, 45]), array([ 8, 11, 16, 24, 33, 36, 40, 42, 44]))\n"
     ]
    }
   ],
   "source": [
    "splits = KFold(n_splits=5, shuffle=True).split(range(46))\n",
    "for split in splits:\n",
    "    print(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index = np.random.randint(0, len(x_test))\n",
    "predictions[0][\"prediction\"].shape\n",
    "# Create a horizontal subplot of the prediction and the ground truth\n",
    "# fig, axs = plt.subplots(1, 2, figsize=(10, 10))\n",
    "# axs[0].imshow(predictions[random_index,:,:,0])\n",
    "# axs[0].set_title('prediction')\n",
    "# axs[1].imshow(x_test[random_index,:,:,0])\n",
    "# axs[1].set_title('ground truth')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation (To DO)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save predictions in correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction for test\n",
    "predictions = []\n",
    "for d in test_data:\n",
    "    prediction = np.array(np.zeros_like(d['video']), dtype=np.bool)\n",
    "    height = prediction.shape[0]\n",
    "    width = prediction.shape[1]\n",
    "    prediction[int(height/2)-50:int(height/2+50), int(width/2)-50:int(width/2+50)] = True\n",
    "    \n",
    "    # DATA Strucure\n",
    "    predictions.append({\n",
    "        'name': d['name'],\n",
    "        'prediction': prediction\n",
    "        }\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
