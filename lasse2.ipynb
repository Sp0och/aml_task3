{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import cv2 as cv\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import KFold\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from PIL import Image as im\n",
    "from skimage.measure import label, regionprops\n",
    "from scipy.ndimage import median_filter\n",
    "from tensorflow.keras import backend as K\n",
    "# import model checkpoint\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "# import canny edge detector\n",
    "from skimage.feature import canny\n",
    "from scipy.ndimage import binary_erosion, binary_dilation, binary_closing, binary_opening, center_of_mass, fourier_ellipsoid, generate_binary_structure"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 32\n",
    "BATCH_SIZE = 8\n",
    "N_AUGMENTATIONS = 10\n",
    "INPUT_SHAPE = (360, 360)\n",
    "SUBMISSION = True\n",
    "TH = 0.5\n",
    "NB_OF_AREAS = 3\n",
    "EROSION_ITERATIONS = 5\n",
    "MODEL_FILE = 'model.hdf5'\n",
    "BEST_MODEL_FILE = 'best_model.hdf5'\n",
    "# env2lmod\n",
    "# module load cuda cudnn python\n",
    "# pip3 install --user --upgrade pip\n",
    "# pip3 install --user --upgrade h5py==3.6.0\n",
    "# pip3 install --user --upgrade numpy==1.21.5\n",
    "# pip3 install --user --upgrade opencv-python==4.6.0.66\n",
    "# pip3 install --user --upgrade scikit-image==0.19.3\n",
    "# pip3 install --user --upgrade scikit-learn==1.0.2\n",
    "# pip3 install --user --upgrade pillow==9.0.0\n",
    "# pip3 install --user --upgrade scipy==1.7.3\n",
    "# pip3 install --user --upgrade tensorflow-gpu==2.8.0\n",
    "# pip3 install --user --upgrade tensorflow==2.8.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_zipped_pickle(filename):\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        loaded_object = pickle.load(f)\n",
    "        return loaded_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_zipped_pickle(obj, filename):\n",
    "    with gzip.open(filename, 'wb') as f:\n",
    "        pickle.dump(obj, f, 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_conv_block(x, n_filters):\n",
    "   x = layers.Conv2D(n_filters, 3, padding=\"same\")(x)\n",
    "   x = layers.BatchNormalization()(x)\n",
    "   x = layers.ReLU()(x)\n",
    "   x = layers.Conv2D(n_filters, 3, padding=\"same\")(x)\n",
    "   x = layers.BatchNormalization()(x)\n",
    "   x = layers.ReLU()(x)\n",
    "   return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_block(x, n_filters):\n",
    "   f = double_conv_block(x, n_filters)\n",
    "   p = layers.MaxPool2D(2)(f)\n",
    "   #p = layers.Dropout(0.3)(p)\n",
    "   return f, p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_block(x, conv_features, n_filters):\n",
    "   x = layers.Conv2DTranspose(n_filters, 2, 2, padding=\"valid\")(x)\n",
    "   x = layers.concatenate([x, conv_features])\n",
    "   #x = layers.Dropout(0.3)(x)\n",
    "   x = double_conv_block(x, n_filters)\n",
    "   return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(m = 4):\n",
    "    inputs = layers.Input(shape=INPUT_SHAPE)\n",
    "    f1, p1 = downsample_block(inputs, 8 * m)\n",
    "    f2, p2 = downsample_block(p1, 16 * m)\n",
    "    f3, p3 = downsample_block(p2, 32 * m)\n",
    "    bottleneck = double_conv_block(p3, 64 * m)\n",
    "    u7 = upsample_block(bottleneck, f3, 32 * m)\n",
    "    u8 = upsample_block(u7, f2, 16 * m)\n",
    "    u9 = upsample_block(u8, f1, 8 * m)\n",
    "    outputs = layers.Conv2D(1, 1, padding=\"valid\", activation = \"sigmoid\")(u9)\n",
    "    return tf.keras.Model(inputs, outputs)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_distance(y_true, y_pred, smooth=100):\n",
    "    \"\"\"Jaccard distance for semantic segmentation.\n",
    "    The loss has been modified to have a smooth gradient as it converges on zero.\n",
    "    This has been shifted so it converges on 0 and is smoothed to avoid exploding\n",
    "    or disappearing gradient.\n",
    "    Jaccard = (|X & Y|)/ (|X|+ |Y| - |X & Y|)\n",
    "            = sum(|A*B|)/(sum(|A|)+sum(|B|)-sum(|A*B|))\n",
    "\n",
    "    # https://github.com/karolzak/keras-unet/tree/master/keras_unet\n",
    "    \"\"\"\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return (1 - jac) * smooth\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datagen():\n",
    "    datagen = ImageDataGenerator(horizontal_flip=True,\n",
    "                    rotation_range=10,\n",
    "                    shear_range=10,\n",
    "                    zoom_range=[0.8, 1.1],\n",
    "                    height_shift_range=0.1,\n",
    "                    width_shift_range=0.1,\n",
    "                    brightness_range=(0.3, 1))\n",
    "    return datagen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(image, mask):\n",
    "    seed = 1\n",
    "    data_gen_args = dict(horizontal_flip=True,\n",
    "                         rotation_range=10,\n",
    "                         shear_range=10,\n",
    "                         zoom_range=[0.8, 1.1],\n",
    "                         height_shift_range=0.1,\n",
    "                         width_shift_range=0.1,\n",
    "                         brightness_range=(0.3, 1))\n",
    "\n",
    "    frame_augmentor = ImageDataGenerator(**data_gen_args)\n",
    "    label_augmentor = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "    myimg = image.reshape((1,) + image.shape + (1,))\n",
    "    mask = mask.reshape((1,) + mask.shape + (1,))\n",
    "\n",
    "    aug_frames = frame_augmentor.flow(myimg, seed=seed, batch_size=1)\n",
    "    aug_labels = label_augmentor.flow(mask, seed=seed, batch_size=1)\n",
    "\n",
    "\n",
    "    return aug_frames, aug_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    X_val=None,\n",
    "    Y_val=None,\n",
    "    nr_augmentations=1,\n",
    "    data_gen_args=dict(\n",
    "        #horizontal_flip=True,\n",
    "        #rotation_range=10,\n",
    "        #zoom_range=0.1,\n",
    "        #height_shift_range=0.1,\n",
    "        #width_shift_range=0.1,\n",
    "        fill_mode='constant'\n",
    "        \n",
    "        # vertical_flip=False,\n",
    "        # shear_range=10,\n",
    "        # zoom_range=[0.8, 1.1],\n",
    "        # brightness_range=(0.3, 1)\n",
    "    )\n",
    "):\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    if(X_val is not None and Y_val is not None):\n",
    "        x_val = []\n",
    "        y_val = []\n",
    "\n",
    "    X_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    Y_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    X_datagen.fit(X_train, augment=True, seed=0)\n",
    "    Y_datagen.fit(Y_train, augment=True, seed=0)\n",
    "    X_train_augmented = X_datagen.flow(X_train, batch_size=BATCH_SIZE, shuffle=True, seed=0)\n",
    "    Y_train_augmented = Y_datagen.flow(Y_train, batch_size=BATCH_SIZE, shuffle=True, seed=0)\n",
    "\n",
    "    if not (X_val is None) and not (Y_val is None):\n",
    "        X_datagen_val = ImageDataGenerator(**data_gen_args)\n",
    "        Y_datagen_val = ImageDataGenerator(**data_gen_args)\n",
    "        X_datagen_val.fit(X_val, augment=False, seed=0)\n",
    "        Y_datagen_val.fit(Y_val, augment=False, seed=0)\n",
    "        X_val_augmented = X_datagen_val.flow(X_val, batch_size=BATCH_SIZE, shuffle=False, seed=0)\n",
    "        Y_val_augmented = Y_datagen_val.flow(Y_val, batch_size=BATCH_SIZE, shuffle=False, seed=0)\n",
    "\n",
    "    #     return zip(X_train_augmented, Y_train_augmented), zip(X_val_augmented, Y_val_augmented)\n",
    "    # else:\n",
    "    #     return zip(X_train_augmented, Y_train_augmented), None\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of Augmentation Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmented_images_visualization(train_data):\n",
    "    train_sample_id = 50\n",
    "    labeled_frame_idx = 1\n",
    "\n",
    "    video = np.copy(train_data[train_sample_id]['video'])\n",
    "    labels = train_data[train_sample_id]['label']\n",
    "    box = train_data[train_sample_id]['box']\n",
    "    labeled_frames = train_data[train_sample_id]['frames']\n",
    "\n",
    "    aug_frames, aug_labels = augment_data(video[:,:,labeled_frames[labeled_frame_idx]], 255*labels[:,:,labeled_frames[labeled_frame_idx]].astype(np.ubyte))\n",
    "\n",
    "    nrow = 4\n",
    "    ncol = 4\n",
    "    # generate samples and plot\n",
    "    fig, ax = plt.subplots(nrows=nrow, ncols=ncol, figsize=(15, 15 * nrow / ncol))\n",
    "\n",
    "    for ox in ax.reshape(-1):\n",
    "        # convert to unsigned integers\n",
    "        image = next(aug_frames)[0].astype('uint8')\n",
    "        mask = next(aug_labels)[0].astype('uint8')\n",
    "        ox.imshow(image)\n",
    "        ox.imshow(mask, alpha=0.5)\n",
    "        ox.axis('off')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loading"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input image with augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmented_image_loading(train_data, test_data, n_augmentations=10):\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    mask = np.zeros(INPUT_SHAPE)\n",
    "    x_test = []\n",
    "    for d in train_data:\n",
    "        for i in d[\"frames\"]:\n",
    "            x = cv2.resize(d[\"video\"][:,:,i], dsize=INPUT_SHAPE[:2])\n",
    "            y = cv2.resize(255 * d[\"label\"][:,:,i].astype(np.ubyte), dsize=INPUT_SHAPE)\n",
    "            x_train.append(x)\n",
    "            y_train.append(y)\n",
    "            mask = np.logical_or(mask, y)\n",
    "\n",
    "            aug_images, aug_masks = augment_data(x, y)\n",
    "            for tt in range(n_augmentations):\n",
    "                x_train.append(cv2.resize(next(aug_images)[0], dsize=(360, 360)))\n",
    "                y_train.append(cv2.resize(next(aug_masks)[0], dsize=(360, 360)))\n",
    "\n",
    "    mask = cv2.morphologyEx(255 * mask.astype(np.ubyte), cv2.MORPH_OPEN, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (50, 50)))\n",
    "    mask = binary_dilation(mask, iterations=10)\n",
    "\n",
    "    for d in test_data:\n",
    "        for i in range(d[\"video\"].shape[2]):\n",
    "            x_test.append(cv2.resize(d[\"video\"][:, :, i], dsize=(360, 360)))\n",
    "\n",
    "    x_train = np.expand_dims(np.array(x_train, dtype=np.single), 3)\n",
    "    y_train = np.expand_dims(np.array(y_train, dtype=np.single), 3) / 255.0\n",
    "    x_test = np.expand_dims(np.array(x_test, dtype=np.single), 3)\n",
    "\n",
    "    return x_train, y_train, x_test, mask\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median Filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_median_filtered(x_train,x_test, median_size=3):\n",
    "    x_train_median_filtered = []\n",
    "    x_test_median_filtered = []\n",
    "    for i in range(x_train.shape[0]):\n",
    "        x_train_median_filtered.append(median_filter(x_train[i,:,:,0], size=median_size))\n",
    "    for i in range(x_test.shape[0]):\n",
    "        x_test_median_filtered.append(median_filter(x_test[i,:,:,0], size=median_size))\n",
    "\n",
    "    x_train_median_filtered = np.expand_dims(np.array(x_train_median_filtered, dtype=np.single), 3)\n",
    "    x_test_median_filtered = np.expand_dims(np.array(x_test_median_filtered, dtype=np.single), 3)\n",
    "\n",
    "    return x_train_median_filtered, x_test_median_filtered\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canny Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_canny_edge_filtered(x_train,x_test):\n",
    "    x_train_canny_edges = []\n",
    "    x_test_canny_edges = []\n",
    "    for i in range(x_train.shape[0]):\n",
    "        x_train_canny_edges.append(canny(x_train[i,:,:,0], sigma=3))\n",
    "\n",
    "    for i in range(x_test.shape[0]):\n",
    "        x_test_canny_edges.append(canny(x_test[i,:,:,0], sigma=3))\n",
    "\n",
    "    x_train_canny_edges = np.expand_dims(np.array(x_train_canny_edges, dtype=np.single), 3)\n",
    "    x_test_canny_edges = np.expand_dims(np.array(x_test_canny_edges, dtype=np.single), 3)\n",
    "\n",
    "    return x_train_canny_edges, x_test_canny_edges\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data as concatenated arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data(train_data, test_data, n_augmentations=10, median_size=3):\n",
    "    x_train, y_train, x_test, mask = augmented_image_loading(train_data, test_data, n_augmentations=n_augmentations)\n",
    "    x_train_median_filtered, x_test_median_filtered = get_median_filtered(x_train, x_test, median_size=median_size)\n",
    "    x_train_canny_edges, x_test_canny_edges = get_canny_edge_filtered(x_train, x_test)\n",
    "\n",
    "    x_train = np.concatenate([x_train, x_train_median_filtered, x_train_canny_edges], axis=3)\n",
    "    x_test = np.concatenate([x_test, x_test_median_filtered, x_test_canny_edges], axis=3)\n",
    "\n",
    "    return x_train, y_train, x_test, mask\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Input data to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train images shape: \", x_train.shape)\n",
    "print(\"train labels shape: \", y_train.shape)\n",
    "print(\"test images shape: \", x_test.shape)\n",
    "# almost the same number for the test images as we consider not only keyframes but have no data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index = np.random.randint(0, x_train.shape[0])\n",
    "# make subplot of the 3 image channels with overlayed mask\n",
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15, 15))\n",
    "ax[0].imshow(x_train[random_index,:,:,0], cmap='gray')\n",
    "ax[0].imshow(y_train[random_index,:,:,0], cmap='gray', alpha=0.5)\n",
    "ax[1].imshow(x_train[random_index,:,:,1], cmap='gray')\n",
    "ax[1].imshow(y_train[random_index,:,:,0], cmap='gray', alpha=0.5)\n",
    "ax[2].imshow(x_train[random_index,:,:,2], cmap='gray')\n",
    "ax[2].imshow(y_train[random_index,:,:,0], cmap='gray', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix seed\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "train_data = load_zipped_pickle(\"train.pkl\")\n",
    "test_data = load_zipped_pickle(\"test.pkl\")\n",
    "\n",
    "x_train, y_train, x_test, mask = get_training_data(train_data, test_data, N_AUGMENTATIONS, median_size=3)\n",
    "\n",
    "amateur = KFold(n_splits=5, shuffle=True).split(range(46))\n",
    "expert = KFold(n_splits=5, shuffle=True).split(range(19))\n",
    "scores = []\n",
    "# TODO fix validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (train_idx_a, val_idx_a), (train_idx_e, val_idx_e) in zip(amateur, expert):\n",
    "    # Get the flag indexes of the training and validation data\n",
    "    flag_train_idx = np.concatenate((train_idx_a, [i + 46 for i in train_idx_e]))\n",
    "    flag_val_idx = np.concatenate((val_idx_a, [i + 46 for i in val_idx_e]))\n",
    "    # For each index add the three frames and their augmentations (11 images per entry => 33 * 65 total)\n",
    "    train_idx = np.array([])\n",
    "    val_idx = np.array([])\n",
    "    for idx in flag_train_idx:\n",
    "        for frame in range(3):\n",
    "            for augm in range(N_AUGMENTATIONS):\n",
    "                # append 33 * idx + 11 * frame + N_AUGMENTATIONS:\n",
    "                train_idx = np.append(train_idx, [33 * idx + 11 * frame + N_AUGMENTATIONS])\n",
    "    for idx in flag_val_idx:\n",
    "        for frame in range(3):\n",
    "            for augm in range(N_AUGMENTATIONS):\n",
    "                val_idx = np.append(val_idx, [33 * idx + 11 * frame + N_AUGMENTATIONS])\n",
    "        \n",
    "    print('------------------------------------------------------------------------------------')\n",
    "    print('Training for fold')\n",
    "    print('------------------------------------------------------------------------------------')\n",
    "    \n",
    "    keras.backend.clear_session()\n",
    "    model = get_model()\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss=keras.losses.BinaryCrossentropy(),\n",
    "        metrics=[tf.keras.metrics.BinaryIoU(target_class_ids=[1], threshold=TH, name=\"IoU\")]\n",
    "    )\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath=MODEL_FILE, \n",
    "        monitor=\"val_IoU\",\n",
    "        verbose=0, \n",
    "        save_best_only=True,\n",
    "        mode=\"max\",\n",
    "        save_weights_only=True\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        x_train[train_idx],\n",
    "        y_train[train_idx],\n",
    "        validation_data=(x_train[val_idx], y_train[val_idx]),\n",
    "        steps_per_epoch=len(x_train[train_idx]) // BATCH_SIZE,\n",
    "        validation_steps=len(x_train[val_idx]) // BATCH_SIZE,\n",
    "        callbacks=[checkpoint],\n",
    "        verbose=1,\n",
    "        epochs=EPOCHS\n",
    "    )\n",
    "\n",
    "    model.load_weights(MODEL_FILE)\n",
    "    pred = np.squeeze(model.predict(x_train[val_idx]))\n",
    "\n",
    "    m = tf.keras.metrics.BinaryIoU(target_class_ids=[1], threshold=TH)\n",
    "    fehlt = 0\n",
    "    for i in range(len(val_idx)):\n",
    "        idx = val_idx[i]\n",
    "        ff = train_data[idx//3][\"frames\"][idx%3]\n",
    "        gt = train_data[idx//3][\"label\"][:,:,ff]\n",
    "        im.fromarray(gt).save(\"pred/\" + str(i) + \"_0.jpg\")\n",
    "        \n",
    "        pp = cv2.resize(255 * pred[i,:,:], dsize=gt.shape[::-1])\n",
    "        pp = pp > (255 * TH)\n",
    "        pp = np.logical_and(cv2.resize(mask.astype(np.ubyte), dsize=gt.shape[::-1]), pp)\n",
    "        im.fromarray(pp).save(\"pred/\" + str(i) + \"_1.jpg\")\n",
    "\n",
    "        lab = label(pp)\n",
    "        rps = regionprops(lab)\n",
    "        area_idx = np.argsort([r.area for r in rps])[::-1]\n",
    "        new_pp = np.zeros_like(pp)\n",
    "        for j in area_idx[:NB_OF_AREAS]:\n",
    "            new_pp[tuple(rps[j].coords.T)] = True\n",
    "        #new_pp = binary_erosion(new_pp, iterations=EROSION_ITERATIONS)\n",
    "        im.fromarray(new_pp).save(\"pred/\" + str(i) + \"_2.jpg\")\n",
    "        \n",
    "        fehlt += np.count_nonzero(np.logical_and(gt, np.logical_not(new_pp)))\n",
    "        m.update_state(gt.astype(np.ubyte), new_pp.astype(np.ubyte))\n",
    "        \n",
    "    print(fehlt)\n",
    "    scores.append(m.result().numpy())\n",
    "    print(\"score: \" + str(scores[-1]))\n",
    "    \n",
    "    if m.result().numpy() == max(scores):\n",
    "        model.save_weights(BEST_MODEL_FILE)\n",
    "    \n",
    "    \n",
    "\n",
    "print(\"total score: \" + str(np.mean(scores)))\n",
    "\n",
    "if SUBMISSION:\n",
    "\n",
    "    predictions = []\n",
    "    model.load_weights(BEST_MODEL_FILE)\n",
    "\n",
    "    for d in test_data:\n",
    "        \n",
    "        x_test = []\n",
    "        for i in range(d[\"video\"].shape[2]):\n",
    "            x_test.append(cv2.resize(d[\"video\"][:,:,i], dsize=INPUT_SHAPE[:2]))\n",
    "        x_test = np.expand_dims(np.array(x_test, dtype=np.single), 3)\n",
    "        \n",
    "        pred = model.predict(x_test)\n",
    "        pred = np.squeeze(pred)\n",
    "        \n",
    "        prediction = np.array(np.zeros_like(d['video']), dtype=bool)\n",
    "        \n",
    "        for i in range(pred.shape[0]):\n",
    "            \n",
    "            pp = cv2.resize(255 * pred[i,:,:], dsize=prediction.shape[::-1][1:])\n",
    "            pp = pp > (255 * TH)\n",
    "            pp = np.logical_and(cv2.resize(mask.astype(np.ubyte), dsize=prediction.shape[::-1][1:]), pp)\n",
    "            pred_img = im.fromarray(pp)\n",
    "            \n",
    "            lab = label(pp)\n",
    "            rps = regionprops(lab)\n",
    "            area_idx = np.argsort([r.area for r in rps])[::-1]\n",
    "            new_pp = np.zeros_like(pp)\n",
    "            for j in area_idx[:NB_OF_AREAS]:\n",
    "                new_pp[tuple(rps[j].coords.T)] = True\n",
    "            #new_pp = binary_erosion(new_pp, iterations=EROSION_ITERATIONS)\n",
    "            new_pred_img = im.fromarray(new_pp)\n",
    "            \n",
    "            prediction[:,:,i] = new_pp\n",
    "        \n",
    "        predictions.append({'name': d['name'], 'prediction': prediction})\n",
    "\n",
    "    save_zipped_pickle(predictions, 'my_predictions.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper Param Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# EPOCHS = [8,8,8,8,8]\n",
    "# BATCH_SIZES = [4,4,4,4,4]\n",
    "# NR_OF_AUGMENTATIONS = [0,5,10,15,20]\n",
    "# LEARNING_RATES = [1e-3,1e-3,1e-3,1e-3,1e-3]\n",
    "# LOSS_FUNCTIONS = [keras.losses.BinaryCrossentropy(),keras.losses.BinaryCrossentropy(),keras.losses.BinaryCrossentropy(),keras.losses.BinaryCrossentropy(),keras.losses.BinaryCrossentropy()]\n",
    "# for fold_nr in range(5):\n",
    "#     print('------------------------------------------------------------------------------------')\n",
    "#     print(f'Training for fold {fold_nr  + 1} ...')\n",
    "#     print(f'BATCH_SIZE: {BATCH_SIZES[fold_nr]}')\n",
    "#     print(f'EPOCHS: {EPOCHS[fold_nr]}')\n",
    "#     print(f'nr_of_augmentations: {NR_OF_AUGMENTATIONS[fold_nr]}')\n",
    "#     print(f'learning_rate: {LEARNING_RATES[fold_nr]}')\n",
    "#     print(f'loss_function: {LOSS_FUNCTIONS[fold_nr]}')\n",
    "#     print('------------------------------------------------------------------------------------')\n",
    "\n",
    "#     keras.backend.clear_session()\n",
    "#     model = get_model(256)\n",
    "#     model.summary()\n",
    "#     print(model.output_shape)\n",
    "\n",
    "#     model.compile(\n",
    "#       optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATES[fold_nr]),\n",
    "#       #loss=keras.losses.CategoricalCrossentropy(),\n",
    "#       loss=LOSS_FUNCTIONS[0],\n",
    "#       metrics=[keras.metrics.BinaryAccuracy(name='accuracy')]\n",
    "#     )\n",
    "# # Fit the model with augmented data\n",
    "#     model.fit(datagen.flow(x_train, y=y_train, batch_size=NR_OF_AUGMENTATIONS[fold_nr], seed=seed, shuffle=False),\n",
    "#             validation_data=(x_val, y_val),\n",
    "#             batch_size=BATCH_SIZES[fold_nr],\n",
    "#             epochs=EPOCHS[fold_nr],\n",
    "#             verbose=2\n",
    "#         )\n",
    "\n",
    "#     #scores = model.evaluate(samples[test_idx], labels[test_idx], verbose=0)\n",
    "#     #f1 = f1_score(np.argmax(labels[test_idx], axis=1), np.argmax(model.predict(samples[test_idx]), axis=1), average='micro')\n",
    "#     #print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%; f1_score of {f1}')\n",
    "#     # break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indexes = []\n",
    "for d in test_data:\n",
    "    test_indexes.append(d[\"video\"].shape[0])\n",
    "\n",
    "test_indexes = np.cumsum(test_indexes)\n",
    "print(test_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split predictions into videos\n",
    "predictions_per_video = np.split(predictions, test_indexes[:-1], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_squeezed = np.squeeze(predictions_per_video)\n",
    "test = np.array(np.zeros_like(predictions_per_video[0][0]), dtype=bool)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros(INPUT_SHAPE)\n",
    "for d in train_data:\n",
    "    for i in d[\"frames\"]:\n",
    "        x = cv2.resize(d[\"video\"][:,:,i], dsize=INPUT_SHAPE[:2])\n",
    "        y = cv2.resize(255 * d[\"label\"][:,:,i].astype(np.ubyte), dsize=INPUT_SHAPE[:2])\n",
    "        mask = np.logical_or(mask, y)\n",
    "\n",
    "mask = cv2.morphologyEx(255 * mask.astype(np.ubyte), cv2.MORPH_OPEN, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (50, 50)))\n",
    "mask = binary_dilation(mask, iterations=10)\n",
    "\n",
    "test = np.array(np.zeros_like(predictions_per_video[0]), dtype=bool)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = load_zipped_pickle(\"sample.pkl\")\n",
    "print(samples[0][\"prediction\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionn = load_zipped_pickle(\"my_predictions.pkl\")\n",
    "print(predictionn[0][\"prediction\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_pp = []\n",
    "for video in predictions_per_video:\n",
    "    prediction = np.array(np.zeros_like(video), dtype=bool)\n",
    "    for frame in video:\n",
    "        # threshold filtering and filter out when outside of expected location\n",
    "        print(prediction.shape)\n",
    "        pp = cv2.resize(255 * frame, dsize=prediction.shape[::-1][1:])\n",
    "        pp = pp > (255 * TH)\n",
    "        pp = np.logical_and(cv2.resize(mask.astype(np.ubyte), dsize=prediction.shape[::-1][1:]), pp)\n",
    "        # pred_img = im.fromarray(pp)\n",
    "    \n",
    "        lab = label(pp)\n",
    "        rps = regionprops(lab)\n",
    "        area_idx = np.argsort([r.area for r in rps])[::-1]\n",
    "        new_pp = np.zeros_like(pp)\n",
    "        for j in area_idx[:NB_OF_AREAS]:\n",
    "            new_pp[tuple(rps[j].coords.T)] = True\n",
    "        #new_pp = binary_erosion(new_pp, iterations=EROSION_ITERATIONS)\n",
    "        new_pred_img = im.fromarray(new_pp)\n",
    "        \n",
    "        prediction[:,:,i] = new_pp\n",
    "    \n",
    "    predictions_pp.append({'name': d['name'], 'prediction': prediction})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    random_index = np.random.randint(0, len(x_train))\n",
    "    enhanced = 255 * train_predictions[random_index,:,:,0]\n",
    "    enhanced = enhanced > 255 * 0.99\n",
    "    # Create a horizontal subplot of xtrain image, ytrain image and enhanced image\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 15))\n",
    "    axs[0].imshow(x_train[random_index,:,:,0])\n",
    "    axs[0].set_title('x_train')\n",
    "    axs[1].imshow(y_train[random_index,:,:,0])\n",
    "    axs[1].set_title('y_train')\n",
    "    axs[2].imshow(enhanced, cmap='gray')\n",
    "    axs[2].set_title('enhanced')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    random_index = np.random.randint(0, len(x_test))\n",
    "    enhanced = 255 * predictions[random_index,:,:,0]\n",
    "    enhanced = enhanced > 255 * 0.99\n",
    "    # Create a horizontal subplot of the two images x_test and enhanced\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 10))\n",
    "    axs[0].imshow(x_test[random_index,:,:,0])\n",
    "    axs[0].set_title('x_test')\n",
    "    axs[1].imshow(enhanced, cmap='gray')\n",
    "    axs[1].set_title('enhanced')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "model = tf.keras.models.load_model('triple_input_model')\n",
    "for d in test_data:\n",
    "    \n",
    "    x_test = []\n",
    "    for i in range(d[\"video\"].shape[2]):\n",
    "        x_test.append(cv2.resize(d[\"video\"][:,:,i], dsize=INPUT_SHAPE))\n",
    "    x_test = np.expand_dims(np.array(x_test, dtype=np.single), 3)\n",
    "\n",
    "    x_train_median_filtered = []\n",
    "    x_test_median_filtered = []\n",
    "    for i in range(x_train.shape[0]):\n",
    "        x_train_median_filtered.append(median_filter(x_train[i,:,:,0], size=3))\n",
    "    for i in range(x_test.shape[0]):\n",
    "        x_test_median_filtered.append(median_filter(x_test[i,:,:,0], size=3))\n",
    "        x_train_canny_edges = []\n",
    "    x_test_canny_edges = []\n",
    "    for i in range(x_train.shape[0]):\n",
    "        x_train_canny_edges.append(canny(x_train[i,:,:,0], sigma=3))\n",
    "\n",
    "    for i in range(x_test.shape[0]):\n",
    "        x_test_canny_edges.append(canny(x_test[i,:,:,0], sigma=3))\n",
    "    x_test = np.concatenate((x_test, np.expand_dims(np.array(x_test_median_filtered, dtype=np.single), 3)), axis=3)\n",
    "    x_test = np.concatenate((x_test, np.expand_dims(np.array(x_test_canny_edges, dtype=np.single), 3)), axis=3)\n",
    "\n",
    "    \n",
    "    pred = model.predict(x_test)\n",
    "    pred = np.squeeze(pred)\n",
    "    \n",
    "    prediction = np.array(np.zeros_like(d['video']), dtype=bool)\n",
    "    print(prediction.shape)\n",
    "    \n",
    "    for i in range(pred.shape[0]):\n",
    "        \n",
    "        pp = cv2.resize(255 * pred[i,:,:], dsize=prediction.shape[::-1][1:])\n",
    "        pp = pp > (255 * TH)\n",
    "        pp = np.logical_and(cv2.resize(mask.astype(np.ubyte), dsize=prediction.shape[::-1][1:]), pp)\n",
    "        pred_img = im.fromarray(pp)\n",
    "        \n",
    "        lab = label(pp)\n",
    "        rps = regionprops(lab)\n",
    "        area_idx = np.argsort([r.area for r in rps])[::-1]\n",
    "        new_pp = np.zeros_like(pp)\n",
    "        for j in area_idx[:NB_OF_AREAS]:\n",
    "            new_pp[tuple(rps[j].coords.T)] = True\n",
    "        #new_pp = binary_erosion(new_pp, iterations=EROSION_ITERATIONS)\n",
    "        new_pred_img = im.fromarray(new_pp)\n",
    "        \n",
    "        prediction[:,:,i] = new_pp\n",
    "    \n",
    "    predictions.append({'name': d['name'], 'prediction': prediction})\n",
    "\n",
    "save_zipped_pickle(predictions, 'my_predictions.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array([1,2] + [3,4])\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 1,  4,  5,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22,\n",
      "       24, 25, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42,\n",
      "       43, 44]), array([ 0,  2,  3,  6, 19, 20, 23, 26, 34, 45]))\n",
      "(array([ 0,  1,  2,  3,  4,  5,  6,  8,  9, 10, 11, 12, 13, 14, 16, 18, 19,\n",
      "       20, 22, 23, 24, 25, 26, 28, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41,\n",
      "       42, 44, 45]), array([ 7, 15, 17, 21, 27, 29, 37, 38, 43]))\n",
      "(array([ 0,  2,  3,  5,  6,  7,  8, 11, 13, 14, 15, 16, 17, 19, 20, 21, 22,\n",
      "       23, 24, 25, 26, 27, 28, 29, 30, 33, 34, 35, 36, 37, 38, 39, 40, 42,\n",
      "       43, 44, 45]), array([ 1,  4,  9, 10, 12, 18, 31, 32, 41]))\n",
      "(array([ 0,  1,  2,  3,  4,  6,  7,  8,  9, 10, 11, 12, 15, 16, 17, 18, 19,\n",
      "       20, 21, 23, 24, 26, 27, 29, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42,\n",
      "       43, 44, 45]), array([ 5, 13, 14, 22, 25, 28, 30, 35, 39]))\n",
      "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  9, 10, 12, 13, 14, 15, 17, 18, 19,\n",
      "       20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 37, 38, 39,\n",
      "       41, 43, 45]), array([ 8, 11, 16, 24, 33, 36, 40, 42, 44]))\n"
     ]
    }
   ],
   "source": [
    "splits = KFold(n_splits=5, shuffle=True).split(range(46))\n",
    "for split in splits:\n",
    "    print(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index = np.random.randint(0, len(x_test))\n",
    "predictions[0][\"prediction\"].shape\n",
    "# Create a horizontal subplot of the prediction and the ground truth\n",
    "# fig, axs = plt.subplots(1, 2, figsize=(10, 10))\n",
    "# axs[0].imshow(predictions[random_index,:,:,0])\n",
    "# axs[0].set_title('prediction')\n",
    "# axs[1].imshow(x_test[random_index,:,:,0])\n",
    "# axs[1].set_title('ground truth')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation (To DO)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save predictions in correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction for test\n",
    "predictions = []\n",
    "for d in test_data:\n",
    "    prediction = np.array(np.zeros_like(d['video']), dtype=np.bool)\n",
    "    height = prediction.shape[0]\n",
    "    width = prediction.shape[1]\n",
    "    prediction[int(height/2)-50:int(height/2+50), int(width/2)-50:int(width/2+50)] = True\n",
    "    \n",
    "    # DATA Strucure\n",
    "    predictions.append({\n",
    "        'name': d['name'],\n",
    "        'prediction': prediction\n",
    "        }\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
