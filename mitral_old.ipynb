{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "#import os\n",
    "#from PIL import Image as im\n",
    "import cv2\n",
    "#import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import torchdata as td\n",
    "#from torchmetrics.functional import jaccard_index\n",
    "#from tensorflow.keras.utils import to_categorical\n",
    "from PIL import Image as im\n",
    "from skimage.measure import label, regionprops\n",
    "#from sklearn.metrics import f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "#from keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_zipped_pickle(filename):\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        loaded_object = pickle.load(f)\n",
    "        return loaded_object\n",
    "\n",
    "def save_zipped_pickle(obj, filename):\n",
    "    with gzip.open(filename, 'wb') as f:\n",
    "        pickle.dump(obj, f, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_conv_block(x, n_filters):\n",
    "   x = layers.Conv2D(n_filters, 3, padding=\"same\")(x)#kernel_initializer = \"he_normal\"\n",
    "   x = layers.BatchNormalization()(x)\n",
    "   x = layers.ReLU()(x)\n",
    "   x = layers.Conv2D(n_filters, 3, padding=\"same\")(x)#kernel_initializer = \"he_normal\"\n",
    "   x = layers.BatchNormalization()(x)\n",
    "   x = layers.ReLU()(x)\n",
    "   return x\n",
    "\n",
    "def downsample_block(x, n_filters):\n",
    "   f = double_conv_block(x, n_filters)\n",
    "   p = layers.MaxPool2D(2)(f)\n",
    "   #p = layers.Dropout(0.3)(p)\n",
    "   return f, p\n",
    "\n",
    "def upsample_block(x, conv_features, n_filters):\n",
    "   x = layers.Conv2DTranspose(n_filters, 2, 2, padding=\"valid\")(x)\n",
    "   x = layers.concatenate([x, conv_features])\n",
    "   #x = layers.Dropout(0.3)(x)\n",
    "   x = double_conv_block(x, n_filters)\n",
    "   return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(img_size):\n",
    "    inputs = layers.Input(shape=img_size+(1,))\n",
    "    \n",
    "    f1, p1 = downsample_block(inputs, 16)\n",
    "    f2, p2 = downsample_block(p1, 32)\n",
    "    f3, p3 = downsample_block(p2, 64)\n",
    "    #f4, p4 = downsample_block(p3, 256)\n",
    "    \n",
    "    #bottleneck = double_conv_block(p4, 512)\n",
    "    bottleneck = double_conv_block(p3, 128)\n",
    "    \n",
    "    #u6 = upsample_block(bottleneck, f4, 256)\n",
    "    u7 = upsample_block(bottleneck, f3, 64)\n",
    "    u8 = upsample_block(u7, f2, 32)\n",
    "    u9 = upsample_block(u8, f1, 16)\n",
    "\n",
    "    outputs = layers.Conv2D(1, 1, padding=\"valid\", activation = \"sigmoid\")(u9)\n",
    "    \n",
    "    unet_model = tf.keras.Model(inputs, outputs, name=\"U-Net\")\n",
    "    \n",
    "    return unet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_zipped_pickle(\"train.pkl\")\n",
    "test_data = load_zipped_pickle(\"test.pkl\")\n",
    "samples = load_zipped_pickle(\"sample.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "for d in train_data:\n",
    "    for i in d[\"frames\"]:\n",
    "        x_train.append(cv2.resize(d[\"video\"][:,:,i], dsize=(360, 360)))\n",
    "        y_train.append(cv2.resize(255 * d[\"label\"][:,:,i].astype(np.ubyte), dsize=(360, 360)))\n",
    "\n",
    "x_train = np.expand_dims(np.array(x_train, dtype=np.single), 3)\n",
    "y_train = np.expand_dims(np.array(y_train, dtype=np.single), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y_train[0,:,:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix seed\n",
    "seed = 1\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 8\n",
    "BATCH_SIZE = 4\n",
    "fold_no = 0\n",
    "for train_idx, test_idx in KFold(n_splits=5, shuffle=True).split(y_train):\n",
    "    \n",
    "    fold_no += 1\n",
    "    print('------------------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    print('------------------------------------------------------------------------------------')\n",
    "    \n",
    "    keras.backend.clear_session()\n",
    "    model = get_model((360, 360))\n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        #loss=keras.losses.CategoricalCrossentropy(),\n",
    "        loss=keras.losses.BinaryCrossentropy(),\n",
    "        metrics=[keras.metrics.BinaryAccuracy(name='accuracy')]\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        x_train[train_idx],\n",
    "        y_train[train_idx],\n",
    "        validation_data=(x_train[test_idx], y_train[test_idx]),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    #scores = model.evaluate(samples[test_idx], labels[test_idx], verbose=0)\n",
    "    #f1 = f1_score(np.argmax(labels[test_idx], axis=1), np.argmax(model.predict(samples[test_idx]), axis=1), average='micro')\n",
    "    #print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%; f1_score of {f1}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_train[test_idx])\n",
    "pred = np.squeeze(pred)\n",
    "\n",
    "TH = 0.999\n",
    "NB_OF_AREAS = 4\n",
    "intersection = 0\n",
    "union = 0\n",
    "fehlt = 0\n",
    "for i in range(39):\n",
    "    idx = test_idx[i]\n",
    "    ff = train_data[idx//3][\"frames\"][idx%3]\n",
    "    gt = train_data[idx//3][\"label\"][:,:,ff]\n",
    "    gt_img = im.fromarray(gt)\n",
    "    \n",
    "    pp = cv2.resize(255 * pred[i,:,:], dsize=gt.shape[::-1])\n",
    "    pp = pp > (255 * TH)    \n",
    "    pred_img = im.fromarray(pp)\n",
    "    \n",
    "    lab = label(pp)\n",
    "    rps = regionprops(lab)\n",
    "    area_idx = np.argsort([r.area for r in rps])[::-1]\n",
    "    new_pp = np.zeros_like(pp)\n",
    "    for j in area_idx[:NB_OF_AREAS]:\n",
    "        new_pp[tuple(rps[j].coords.T)] = True\n",
    "    new_pred_img = im.fromarray(new_pp)\n",
    "    \n",
    "    fehlt += np.count_nonzero(np.logical_and(gt, np.logical_not(new_pp)))\n",
    "    intersection += np.count_nonzero(np.logical_and(gt, new_pp))\n",
    "    union += np.count_nonzero(np.logical_or(gt, new_pp))\n",
    "    \n",
    "print(fehlt)\n",
    "print(\"score:\")\n",
    "print(intersection / union)\n",
    "\n",
    "#pred = im.fromarray((np.squeeze(model.predict(x_train[16:17]))>0.8))\n",
    "#gt = im.fromarray(cv2.resize(255 * train_data[5][\"label\"][:,:,51].astype(np.ubyte), dsize=(360, 360)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10 (default, Mar 15 2022, 12:22:08) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
